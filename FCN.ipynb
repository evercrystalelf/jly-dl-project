{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31422c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from math import nan\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,StratifiedKFold,RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43376724",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(15)\n",
    "tf.random.set_seed(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f40c9d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>INF_ANAM</th>\n",
       "      <th>STENOK_AN</th>\n",
       "      <th>FK_STENOK</th>\n",
       "      <th>IBS_POST</th>\n",
       "      <th>GB</th>\n",
       "      <th>SIM_GIPERT</th>\n",
       "      <th>DLIT_AG</th>\n",
       "      <th>ZSN_A</th>\n",
       "      <th>...</th>\n",
       "      <th>LID_KB</th>\n",
       "      <th>NITR_S</th>\n",
       "      <th>LID_S_n</th>\n",
       "      <th>B_BLOK_S_n</th>\n",
       "      <th>ANT_CA_S_n</th>\n",
       "      <th>GEPAR_S_n</th>\n",
       "      <th>ASP_S_n</th>\n",
       "      <th>TIKL_S_n</th>\n",
       "      <th>TRENT_S_n</th>\n",
       "      <th>LET_IS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>73.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>73.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1360 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AGE  SEX  INF_ANAM  STENOK_AN  FK_STENOK  IBS_POST   GB  SIM_GIPERT  \\\n",
       "1414  60.0    0       0.0        5.0        2.0       1.0  2.0         0.0   \n",
       "227   57.0    0       1.0        1.0        2.0       2.0  2.0         0.0   \n",
       "280   52.0    1       1.0        0.0        0.0       2.0  2.0         0.0   \n",
       "1538  73.0    0       1.0        6.0        3.0       NaN  2.0         0.0   \n",
       "1418  78.0    0       0.0        2.0        2.0       2.0  2.0         0.0   \n",
       "...    ...  ...       ...        ...        ...       ...  ...         ...   \n",
       "274   55.0    1       3.0        0.0        0.0       2.0  2.0         0.0   \n",
       "238   73.0    1       1.0        4.0        2.0       2.0  2.0         0.0   \n",
       "1444  65.0    1       0.0        0.0        0.0       0.0  0.0         0.0   \n",
       "409   75.0    0       0.0        0.0        0.0       2.0  2.0         0.0   \n",
       "444   42.0    1       0.0        1.0        2.0       1.0  0.0         0.0   \n",
       "\n",
       "      DLIT_AG  ZSN_A  ...  LID_KB  NITR_S  LID_S_n  B_BLOK_S_n  ANT_CA_S_n  \\\n",
       "1414      6.0    0.0  ...     NaN     0.0      0.0         0.0         1.0   \n",
       "227       6.0    0.0  ...     0.0     0.0      0.0         0.0         0.0   \n",
       "280       2.0    0.0  ...     0.0     0.0      1.0         0.0         1.0   \n",
       "1538      6.0    4.0  ...     1.0     1.0      0.0         0.0         1.0   \n",
       "1418      NaN    0.0  ...     NaN     0.0      0.0         0.0         0.0   \n",
       "...       ...    ...  ...     ...     ...      ...         ...         ...   \n",
       "274       1.0    0.0  ...     0.0     0.0      0.0         1.0         0.0   \n",
       "238       NaN    0.0  ...     0.0     0.0      0.0         0.0         1.0   \n",
       "1444      0.0    NaN  ...     0.0     0.0      0.0         0.0         1.0   \n",
       "409       2.0    0.0  ...     1.0     1.0      0.0         0.0         1.0   \n",
       "444       0.0    0.0  ...     NaN     0.0      0.0         0.0         0.0   \n",
       "\n",
       "      GEPAR_S_n  ASP_S_n  TIKL_S_n  TRENT_S_n  LET_IS  \n",
       "1414        1.0      1.0       0.0        0.0       0  \n",
       "227         1.0      1.0       0.0        0.0       0  \n",
       "280         0.0      1.0       0.0        0.0       0  \n",
       "1538        0.0      1.0       0.0        0.0       1  \n",
       "1418        0.0      0.0       0.0        0.0       0  \n",
       "...         ...      ...       ...        ...     ...  \n",
       "274         1.0      1.0       0.0        0.0       0  \n",
       "238         1.0      0.0       0.0        0.0       0  \n",
       "1444        0.0      0.0       0.0        1.0       1  \n",
       "409         1.0      1.0       0.0        0.0       0  \n",
       "444         1.0      1.0       0.0        1.0       0  \n",
       "\n",
       "[1360 rows x 99 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data and see how it looks like\n",
    "train = pd.read_csv('train', index_col = 0)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5a612bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check this because when running Onehotencoder has problems. May need to change to integer or stings\n",
    "# train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a95076c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE           6\n",
       "SEX           0\n",
       "INF_ANAM      4\n",
       "STENOK_AN    90\n",
       "FK_STENOK    62\n",
       "             ..\n",
       "GEPAR_S_n    12\n",
       "ASP_S_n      12\n",
       "TIKL_S_n     11\n",
       "TRENT_S_n    11\n",
       "LET_IS        0\n",
       "Length: 99, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "127cde3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1360 entries, 1414 to 444\n",
      "Data columns (total 99 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   AGE            1354 non-null   float64\n",
      " 1   SEX            1360 non-null   int64  \n",
      " 2   INF_ANAM       1356 non-null   float64\n",
      " 3   STENOK_AN      1270 non-null   float64\n",
      " 4   FK_STENOK      1298 non-null   float64\n",
      " 5   IBS_POST       1317 non-null   float64\n",
      " 6   GB             1353 non-null   float64\n",
      " 7   SIM_GIPERT     1353 non-null   float64\n",
      " 8   DLIT_AG        1165 non-null   float64\n",
      " 9   ZSN_A          1315 non-null   float64\n",
      " 10  nr_11          1342 non-null   float64\n",
      " 11  nr_01          1342 non-null   float64\n",
      " 12  nr_02          1342 non-null   float64\n",
      " 13  nr_03          1342 non-null   float64\n",
      " 14  nr_04          1342 non-null   float64\n",
      " 15  nr_07          1342 non-null   float64\n",
      " 16  nr_08          1342 non-null   float64\n",
      " 17  np_01          1346 non-null   float64\n",
      " 18  np_04          1346 non-null   float64\n",
      " 19  np_05          1346 non-null   float64\n",
      " 20  np_07          1346 non-null   float64\n",
      " 21  np_08          1346 non-null   float64\n",
      " 22  np_09          1346 non-null   float64\n",
      " 23  np_10          1346 non-null   float64\n",
      " 24  endocr_01      1353 non-null   float64\n",
      " 25  endocr_02      1353 non-null   float64\n",
      " 26  endocr_03      1353 non-null   float64\n",
      " 27  zab_leg_01     1354 non-null   float64\n",
      " 28  zab_leg_02     1354 non-null   float64\n",
      " 29  zab_leg_03     1354 non-null   float64\n",
      " 30  zab_leg_04     1354 non-null   float64\n",
      " 31  zab_leg_06     1354 non-null   float64\n",
      " 32  S_AD_ORIT      1140 non-null   float64\n",
      " 33  D_AD_ORIT      1140 non-null   float64\n",
      " 34  O_L_POST       1350 non-null   float64\n",
      " 35  K_SH_POST      1348 non-null   float64\n",
      " 36  MP_TP_POST     1348 non-null   float64\n",
      " 37  SVT_POST       1350 non-null   float64\n",
      " 38  GT_POST        1350 non-null   float64\n",
      " 39  FIB_G_POST     1350 non-null   float64\n",
      " 40  ant_im         1301 non-null   float64\n",
      " 41  lat_im         1304 non-null   float64\n",
      " 42  inf_im         1302 non-null   float64\n",
      " 43  post_im        1307 non-null   float64\n",
      " 44  IM_PG_P        1360 non-null   float64\n",
      " 45  ritm_ecg_p_01  1234 non-null   float64\n",
      " 46  ritm_ecg_p_02  1234 non-null   float64\n",
      " 47  ritm_ecg_p_04  1234 non-null   float64\n",
      " 48  ritm_ecg_p_06  1234 non-null   float64\n",
      " 49  ritm_ecg_p_07  1234 non-null   float64\n",
      " 50  ritm_ecg_p_08  1234 non-null   float64\n",
      " 51  n_r_ecg_p_01   1266 non-null   float64\n",
      " 52  n_r_ecg_p_02   1266 non-null   float64\n",
      " 53  n_r_ecg_p_03   1266 non-null   float64\n",
      " 54  n_r_ecg_p_04   1266 non-null   float64\n",
      " 55  n_r_ecg_p_05   1266 non-null   float64\n",
      " 56  n_r_ecg_p_06   1266 non-null   float64\n",
      " 57  n_r_ecg_p_08   1266 non-null   float64\n",
      " 58  n_r_ecg_p_09   1266 non-null   float64\n",
      " 59  n_r_ecg_p_10   1266 non-null   float64\n",
      " 60  n_p_ecg_p_01   1266 non-null   float64\n",
      " 61  n_p_ecg_p_03   1266 non-null   float64\n",
      " 62  n_p_ecg_p_04   1266 non-null   float64\n",
      " 63  n_p_ecg_p_05   1266 non-null   float64\n",
      " 64  n_p_ecg_p_06   1266 non-null   float64\n",
      " 65  n_p_ecg_p_07   1266 non-null   float64\n",
      " 66  n_p_ecg_p_08   1266 non-null   float64\n",
      " 67  n_p_ecg_p_09   1266 non-null   float64\n",
      " 68  n_p_ecg_p_10   1266 non-null   float64\n",
      " 69  n_p_ecg_p_11   1266 non-null   float64\n",
      " 70  n_p_ecg_p_12   1266 non-null   float64\n",
      " 71  fibr_ter_01    1351 non-null   float64\n",
      " 72  fibr_ter_02    1351 non-null   float64\n",
      " 73  fibr_ter_03    1351 non-null   float64\n",
      " 74  fibr_ter_05    1351 non-null   float64\n",
      " 75  fibr_ter_06    1351 non-null   float64\n",
      " 76  fibr_ter_07    1351 non-null   float64\n",
      " 77  fibr_ter_08    1351 non-null   float64\n",
      " 78  GIPO_K         1054 non-null   float64\n",
      " 79  K_BLOOD        1052 non-null   float64\n",
      " 80  GIPER_NA       1049 non-null   float64\n",
      " 81  NA_BLOOD       1049 non-null   float64\n",
      " 82  ALT_BLOOD      1131 non-null   float64\n",
      " 83  AST_BLOOD      1130 non-null   float64\n",
      " 84  L_BLOOD        1257 non-null   float64\n",
      " 85  ROE            1191 non-null   float64\n",
      " 86  TIME_B_S       1260 non-null   float64\n",
      " 87  NA_KB          840 non-null    float64\n",
      " 88  NOT_NA_KB      813 non-null    float64\n",
      " 89  LID_KB         821 non-null    float64\n",
      " 90  NITR_S         1355 non-null   float64\n",
      " 91  LID_S_n        1354 non-null   float64\n",
      " 92  B_BLOK_S_n     1353 non-null   float64\n",
      " 93  ANT_CA_S_n     1352 non-null   float64\n",
      " 94  GEPAR_S_n      1348 non-null   float64\n",
      " 95  ASP_S_n        1348 non-null   float64\n",
      " 96  TIKL_S_n       1349 non-null   float64\n",
      " 97  TRENT_S_n      1349 non-null   float64\n",
      " 98  LET_IS         1360 non-null   int64  \n",
      "dtypes: float64(97), int64(2)\n",
      "memory usage: 1.0 MB\n"
     ]
    }
   ],
   "source": [
    "# check if already dropped the features with high rate (more than 50%) of NaN values, and looks already dropped\n",
    "newtrain = train.loc[:, (train.isnull().sum(axis=0) < 1700/2)]\n",
    "newtrain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0c632a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation: fill in with median for continuous features \n",
    "newtrain.fillna(newtrain[['AGE', 'INF_ANAM', 'STENOK_AN', 'FK_STENOK', 'IBS_POST', 'GB', 'DLIT_AG', 'ZSN_A',\n",
    "                         'S_AD_ORIT', 'D_AD_ORIT', 'ant_im', 'lat_im', 'inf_im', 'post_im', 'K_BLOOD',\n",
    "                         'NA_BLOOD', 'ALT_BLOOD', 'AST_BLOOD', 'L_BLOOD', 'ROE', 'TIME_B_S']].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "972b9eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation: fill in with mode for categorical features\n",
    "for column in newtrain[newtrain.columns[~newtrain.columns.isin(['AGE', 'INF_ANAM', 'STENOK_AN', 'FK_STENOK', 'IBS_POST', 'GB', 'DLIT_AG', 'ZSN_A',\n",
    "                         'S_AD_ORIT', 'D_AD_ORIT', 'ant_im', 'lat_im', 'inf_im', 'post_im', 'K_BLOOD',\n",
    "                         'NA_BLOOD', 'ALT_BLOOD', 'AST_BLOOD', 'L_BLOOD', 'ROE', 'TIME_B_S'])]]:\n",
    "    newtrain[column].fillna(newtrain[column].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93a41d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE          0\n",
       "SEX          0\n",
       "INF_ANAM     0\n",
       "STENOK_AN    0\n",
       "FK_STENOK    0\n",
       "            ..\n",
       "GEPAR_S_n    0\n",
       "ASP_S_n      0\n",
       "TIKL_S_n     0\n",
       "TRENT_S_n    0\n",
       "LET_IS       0\n",
       "Length: 99, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if successfully fill in\n",
    "newtrain.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b39bd646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newtrain[['INF_ANAM', 'STENOK_AN', 'FK_STENOK', 'IBS_POST', 'GB', 'DLIT_AG', 'ZSN_A', 'ant_im', 'lat_im', 'inf_im', 'post_im',\\\n",
    "#  'TIME_B_S']]=newtrain[['INF_ANAM', 'STENOK_AN', 'FK_STENOK', 'IBS_POST', 'GB', 'DLIT_AG', 'ZSN_A', 'ant_im', 'lat_im', 'inf_im', 'post_im',\\\n",
    "#  'TIME_B_S']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a23f9e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#newtrain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d1a2c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate X_train and y_train\n",
    "X_train = newtrain.loc[:, newtrain.columns!='LET_IS']\n",
    "y_train = pd.Series(newtrain['LET_IS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a965d29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>INF_ANAM</th>\n",
       "      <th>STENOK_AN</th>\n",
       "      <th>FK_STENOK</th>\n",
       "      <th>IBS_POST</th>\n",
       "      <th>GB</th>\n",
       "      <th>SIM_GIPERT</th>\n",
       "      <th>DLIT_AG</th>\n",
       "      <th>ZSN_A</th>\n",
       "      <th>...</th>\n",
       "      <th>NOT_NA_KB</th>\n",
       "      <th>LID_KB</th>\n",
       "      <th>NITR_S</th>\n",
       "      <th>LID_S_n</th>\n",
       "      <th>B_BLOK_S_n</th>\n",
       "      <th>ANT_CA_S_n</th>\n",
       "      <th>GEPAR_S_n</th>\n",
       "      <th>ASP_S_n</th>\n",
       "      <th>TIKL_S_n</th>\n",
       "      <th>TRENT_S_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>73.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>73.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1360 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AGE  SEX  INF_ANAM  STENOK_AN  FK_STENOK  IBS_POST   GB  SIM_GIPERT  \\\n",
       "1414  60.0    0       0.0        5.0        2.0       1.0  2.0         0.0   \n",
       "227   57.0    0       1.0        1.0        2.0       2.0  2.0         0.0   \n",
       "280   52.0    1       1.0        0.0        0.0       2.0  2.0         0.0   \n",
       "1538  73.0    0       1.0        6.0        3.0       1.0  2.0         0.0   \n",
       "1418  78.0    0       0.0        2.0        2.0       2.0  2.0         0.0   \n",
       "...    ...  ...       ...        ...        ...       ...  ...         ...   \n",
       "274   55.0    1       3.0        0.0        0.0       2.0  2.0         0.0   \n",
       "238   73.0    1       1.0        4.0        2.0       2.0  2.0         0.0   \n",
       "1444  65.0    1       0.0        0.0        0.0       0.0  0.0         0.0   \n",
       "409   75.0    0       0.0        0.0        0.0       2.0  2.0         0.0   \n",
       "444   42.0    1       0.0        1.0        2.0       1.0  0.0         0.0   \n",
       "\n",
       "      DLIT_AG  ZSN_A  ...  NOT_NA_KB  LID_KB  NITR_S  LID_S_n  B_BLOK_S_n  \\\n",
       "1414      6.0    0.0  ...        1.0     0.0     0.0      0.0         0.0   \n",
       "227       6.0    0.0  ...        1.0     0.0     0.0      0.0         0.0   \n",
       "280       2.0    0.0  ...        1.0     0.0     0.0      1.0         0.0   \n",
       "1538      6.0    4.0  ...        1.0     1.0     1.0      0.0         0.0   \n",
       "1418      3.0    0.0  ...        1.0     0.0     0.0      0.0         0.0   \n",
       "...       ...    ...  ...        ...     ...     ...      ...         ...   \n",
       "274       1.0    0.0  ...        0.0     0.0     0.0      0.0         1.0   \n",
       "238       3.0    0.0  ...        1.0     0.0     0.0      0.0         0.0   \n",
       "1444      0.0    0.0  ...        0.0     0.0     0.0      0.0         0.0   \n",
       "409       2.0    0.0  ...        1.0     1.0     1.0      0.0         0.0   \n",
       "444       0.0    0.0  ...        1.0     0.0     0.0      0.0         0.0   \n",
       "\n",
       "      ANT_CA_S_n  GEPAR_S_n  ASP_S_n  TIKL_S_n  TRENT_S_n  \n",
       "1414         1.0        1.0      1.0       0.0        0.0  \n",
       "227          0.0        1.0      1.0       0.0        0.0  \n",
       "280          1.0        0.0      1.0       0.0        0.0  \n",
       "1538         1.0        0.0      1.0       0.0        0.0  \n",
       "1418         0.0        0.0      0.0       0.0        0.0  \n",
       "...          ...        ...      ...       ...        ...  \n",
       "274          0.0        1.0      1.0       0.0        0.0  \n",
       "238          1.0        1.0      0.0       0.0        0.0  \n",
       "1444         1.0        0.0      0.0       0.0        1.0  \n",
       "409          1.0        1.0      1.0       0.0        0.0  \n",
       "444          0.0        1.0      1.0       0.0        1.0  \n",
       "\n",
       "[1360 rows x 98 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5d3a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of continuous and binary columns\n",
    "continuous_col=['AGE',\n",
    " 'S_AD_ORIT',\n",
    " 'D_AD_ORIT',\n",
    " 'K_BLOOD',\n",
    " 'NA_BLOOD',\n",
    " 'ALT_BLOOD',\n",
    " 'AST_BLOOD',\n",
    " 'L_BLOOD',\n",
    " 'ROE',\n",
    " 'INF_ANAM',\n",
    " 'STENOK_AN',\n",
    " 'FK_STENOK',\n",
    " 'IBS_POST',\n",
    " 'GB',\n",
    " 'DLIT_AG',\n",
    " 'ZSN_A',\n",
    " 'ant_im',\n",
    " 'lat_im',\n",
    " 'inf_im',\n",
    " 'post_im',\n",
    " 'TIME_B_S']\n",
    "\n",
    "binary_col = list(X_train.drop(continuous_col, axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e42887d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalor=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "617b268d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>S_AD_ORIT</th>\n",
       "      <th>D_AD_ORIT</th>\n",
       "      <th>K_BLOOD</th>\n",
       "      <th>NA_BLOOD</th>\n",
       "      <th>ALT_BLOOD</th>\n",
       "      <th>AST_BLOOD</th>\n",
       "      <th>L_BLOOD</th>\n",
       "      <th>ROE</th>\n",
       "      <th>INF_ANAM</th>\n",
       "      <th>...</th>\n",
       "      <th>FK_STENOK</th>\n",
       "      <th>IBS_POST</th>\n",
       "      <th>GB</th>\n",
       "      <th>DLIT_AG</th>\n",
       "      <th>ZSN_A</th>\n",
       "      <th>ant_im</th>\n",
       "      <th>lat_im</th>\n",
       "      <th>inf_im</th>\n",
       "      <th>post_im</th>\n",
       "      <th>TIME_B_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>60.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.22</td>\n",
       "      <td>10.8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>57.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>52.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.30</td>\n",
       "      <td>6.9</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>73.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>78.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4.9</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>55.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.30</td>\n",
       "      <td>6.9</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>73.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.40</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>65.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.22</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>75.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.26</td>\n",
       "      <td>5.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>42.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.22</td>\n",
       "      <td>7.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1360 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AGE  S_AD_ORIT  D_AD_ORIT  K_BLOOD  NA_BLOOD  ALT_BLOOD  AST_BLOOD  \\\n",
       "1414  60.0      190.0      100.0      4.1     130.0       0.38       0.22   \n",
       "227   57.0      120.0       80.0      3.5     130.0       0.45       0.15   \n",
       "280   52.0      130.0       80.0      4.4     144.0       0.61       0.30   \n",
       "1538  73.0      130.0      100.0      5.4     130.0       0.75       0.15   \n",
       "1418  78.0      130.0       80.0      7.3     153.0       0.22       0.15   \n",
       "...    ...        ...        ...      ...       ...        ...        ...   \n",
       "274   55.0      140.0       90.0      4.1     136.0       0.38       0.30   \n",
       "238   73.0      110.0       70.0      4.1     136.0       0.45       0.40   \n",
       "1444  65.0      100.0       60.0      4.4     132.0       0.38       0.22   \n",
       "409   75.0      220.0      120.0      3.5     136.0       0.38       0.26   \n",
       "444   42.0      130.0       80.0      5.2     144.0       0.68       0.22   \n",
       "\n",
       "      L_BLOOD   ROE  INF_ANAM  ...  FK_STENOK  IBS_POST   GB  DLIT_AG  ZSN_A  \\\n",
       "1414     10.8   9.0       0.0  ...        2.0       1.0  2.0      6.0    0.0   \n",
       "227       5.1  10.0       1.0  ...        2.0       2.0  2.0      6.0    0.0   \n",
       "280       6.9  13.0       1.0  ...        0.0       2.0  2.0      2.0    0.0   \n",
       "1538     10.2  18.0       1.0  ...        3.0       1.0  2.0      6.0    4.0   \n",
       "1418      4.9  53.0       0.0  ...        2.0       2.0  2.0      3.0    0.0   \n",
       "...       ...   ...       ...  ...        ...       ...  ...      ...    ...   \n",
       "274       6.9  22.0       3.0  ...        0.0       2.0  2.0      1.0    0.0   \n",
       "238       5.0   3.0       1.0  ...        2.0       2.0  2.0      3.0    0.0   \n",
       "1444      8.5   9.0       0.0  ...        0.0       0.0  0.0      0.0    0.0   \n",
       "409       5.9  18.0       0.0  ...        0.0       2.0  2.0      2.0    0.0   \n",
       "444       7.9   4.0       0.0  ...        2.0       1.0  0.0      0.0    0.0   \n",
       "\n",
       "      ant_im  lat_im  inf_im  post_im  TIME_B_S  \n",
       "1414     0.0     0.0     3.0      1.0       7.0  \n",
       "227      0.0     0.0     3.0      0.0       3.0  \n",
       "280      0.0     0.0     3.0      0.0       9.0  \n",
       "1538     1.0     1.0     0.0      0.0       3.0  \n",
       "1418     1.0     1.0     0.0      0.0       2.0  \n",
       "...      ...     ...     ...      ...       ...  \n",
       "274      3.0     1.0     0.0      0.0       7.0  \n",
       "238      0.0     0.0     2.0      0.0       2.0  \n",
       "1444     4.0     1.0     0.0      0.0       9.0  \n",
       "409      4.0     1.0     4.0      0.0       3.0  \n",
       "444      1.0     1.0     0.0      0.0       4.0  \n",
       "\n",
       "[1360 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check continuous columns\n",
    "X_train[continuous_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42ae6bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>S_AD_ORIT</th>\n",
       "      <th>D_AD_ORIT</th>\n",
       "      <th>K_BLOOD</th>\n",
       "      <th>NA_BLOOD</th>\n",
       "      <th>ALT_BLOOD</th>\n",
       "      <th>AST_BLOOD</th>\n",
       "      <th>L_BLOOD</th>\n",
       "      <th>ROE</th>\n",
       "      <th>INF_ANAM</th>\n",
       "      <th>...</th>\n",
       "      <th>FK_STENOK</th>\n",
       "      <th>IBS_POST</th>\n",
       "      <th>GB</th>\n",
       "      <th>DLIT_AG</th>\n",
       "      <th>ZSN_A</th>\n",
       "      <th>ant_im</th>\n",
       "      <th>lat_im</th>\n",
       "      <th>inf_im</th>\n",
       "      <th>post_im</th>\n",
       "      <th>TIME_B_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.117845</td>\n",
       "      <td>0.085308</td>\n",
       "      <td>0.339768</td>\n",
       "      <td>0.057554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.469697</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.141414</td>\n",
       "      <td>0.052133</td>\n",
       "      <td>0.119691</td>\n",
       "      <td>0.064748</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.195286</td>\n",
       "      <td>0.123223</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.086331</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.525424</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.052133</td>\n",
       "      <td>0.316602</td>\n",
       "      <td>0.122302</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.063973</td>\n",
       "      <td>0.052133</td>\n",
       "      <td>0.111969</td>\n",
       "      <td>0.374101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.439394</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.117845</td>\n",
       "      <td>0.123223</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.151079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.141414</td>\n",
       "      <td>0.170616</td>\n",
       "      <td>0.115830</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.117845</td>\n",
       "      <td>0.085308</td>\n",
       "      <td>0.250965</td>\n",
       "      <td>0.057554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.117845</td>\n",
       "      <td>0.104265</td>\n",
       "      <td>0.150579</td>\n",
       "      <td>0.122302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.491525</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.218855</td>\n",
       "      <td>0.085308</td>\n",
       "      <td>0.227799</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1360 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AGE  S_AD_ORIT  D_AD_ORIT   K_BLOOD  NA_BLOOD  ALT_BLOOD  \\\n",
       "1414  0.515152   0.730769   0.526316  0.305085  0.250000   0.117845   \n",
       "227   0.469697   0.461538   0.421053  0.203390  0.250000   0.141414   \n",
       "280   0.393939   0.500000   0.421053  0.355932  0.519231   0.195286   \n",
       "1538  0.712121   0.500000   0.526316  0.525424  0.250000   0.242424   \n",
       "1418  0.787879   0.500000   0.421053  0.847458  0.692308   0.063973   \n",
       "...        ...        ...        ...       ...       ...        ...   \n",
       "274   0.439394   0.538462   0.473684  0.305085  0.365385   0.117845   \n",
       "238   0.712121   0.423077   0.368421  0.305085  0.365385   0.141414   \n",
       "1444  0.590909   0.384615   0.315789  0.355932  0.288462   0.117845   \n",
       "409   0.742424   0.846154   0.631579  0.203390  0.365385   0.117845   \n",
       "444   0.242424   0.500000   0.421053  0.491525  0.519231   0.218855   \n",
       "\n",
       "      AST_BLOOD   L_BLOOD       ROE  INF_ANAM  ...  FK_STENOK  IBS_POST  \\\n",
       "1414   0.085308  0.339768  0.057554  0.000000  ...       0.50       0.5   \n",
       "227    0.052133  0.119691  0.064748  0.333333  ...       0.50       1.0   \n",
       "280    0.123223  0.189189  0.086331  0.333333  ...       0.00       1.0   \n",
       "1538   0.052133  0.316602  0.122302  0.333333  ...       0.75       0.5   \n",
       "1418   0.052133  0.111969  0.374101  0.000000  ...       0.50       1.0   \n",
       "...         ...       ...       ...       ...  ...        ...       ...   \n",
       "274    0.123223  0.189189  0.151079  1.000000  ...       0.00       1.0   \n",
       "238    0.170616  0.115830  0.014388  0.333333  ...       0.50       1.0   \n",
       "1444   0.085308  0.250965  0.057554  0.000000  ...       0.00       0.0   \n",
       "409    0.104265  0.150579  0.122302  0.000000  ...       0.00       1.0   \n",
       "444    0.085308  0.227799  0.021583  0.000000  ...       0.50       0.5   \n",
       "\n",
       "            GB   DLIT_AG  ZSN_A  ant_im  lat_im  inf_im  post_im  TIME_B_S  \n",
       "1414  0.666667  0.857143    0.0    0.00    0.00    0.75     0.25     0.750  \n",
       "227   0.666667  0.857143    0.0    0.00    0.00    0.75     0.00     0.250  \n",
       "280   0.666667  0.285714    0.0    0.00    0.00    0.75     0.00     1.000  \n",
       "1538  0.666667  0.857143    1.0    0.25    0.25    0.00     0.00     0.250  \n",
       "1418  0.666667  0.428571    0.0    0.25    0.25    0.00     0.00     0.125  \n",
       "...        ...       ...    ...     ...     ...     ...      ...       ...  \n",
       "274   0.666667  0.142857    0.0    0.75    0.25    0.00     0.00     0.750  \n",
       "238   0.666667  0.428571    0.0    0.00    0.00    0.50     0.00     0.125  \n",
       "1444  0.000000  0.000000    0.0    1.00    0.25    0.00     0.00     1.000  \n",
       "409   0.666667  0.285714    0.0    1.00    0.25    1.00     0.00     0.250  \n",
       "444   0.000000  0.000000    0.0    0.25    0.25    0.00     0.00     0.375  \n",
       "\n",
       "[1360 rows x 21 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit_transform values of continuous columns in X_train\n",
    "continue_df=pd.DataFrame(scalor.fit_transform(X_train[continuous_col].to_numpy()), columns=['AGE', 'S_AD_ORIT', 'D_AD_ORIT', 'K_BLOOD', 'NA_BLOOD',\\\n",
    " 'ALT_BLOOD', 'AST_BLOOD', 'L_BLOOD', 'ROE', 'INF_ANAM', 'STENOK_AN', 'FK_STENOK', 'IBS_POST', 'GB', 'DLIT_AG', 'ZSN_A',\\\n",
    " 'ant_im', 'lat_im', 'inf_im', 'post_im', 'TIME_B_S'], index=X_train.index)\n",
    "continue_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18741b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>SIM_GIPERT</th>\n",
       "      <th>nr_11</th>\n",
       "      <th>nr_01</th>\n",
       "      <th>nr_02</th>\n",
       "      <th>nr_03</th>\n",
       "      <th>nr_04</th>\n",
       "      <th>nr_07</th>\n",
       "      <th>nr_08</th>\n",
       "      <th>np_01</th>\n",
       "      <th>...</th>\n",
       "      <th>NOT_NA_KB</th>\n",
       "      <th>LID_KB</th>\n",
       "      <th>NITR_S</th>\n",
       "      <th>LID_S_n</th>\n",
       "      <th>B_BLOK_S_n</th>\n",
       "      <th>ANT_CA_S_n</th>\n",
       "      <th>GEPAR_S_n</th>\n",
       "      <th>ASP_S_n</th>\n",
       "      <th>TIKL_S_n</th>\n",
       "      <th>TRENT_S_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1360 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SEX  SIM_GIPERT  nr_11  nr_01  nr_02  nr_03  nr_04  nr_07  nr_08  np_01  \\\n",
       "1414    0         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "227     0         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "280     1         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1538    0         0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0   \n",
       "1418    0         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...   ...         ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "274     1         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "238     1         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1444    1         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "409     0         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "444     1         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      ...  NOT_NA_KB  LID_KB  NITR_S  LID_S_n  B_BLOK_S_n  ANT_CA_S_n  \\\n",
       "1414  ...        1.0     0.0     0.0      0.0         0.0         1.0   \n",
       "227   ...        1.0     0.0     0.0      0.0         0.0         0.0   \n",
       "280   ...        1.0     0.0     0.0      1.0         0.0         1.0   \n",
       "1538  ...        1.0     1.0     1.0      0.0         0.0         1.0   \n",
       "1418  ...        1.0     0.0     0.0      0.0         0.0         0.0   \n",
       "...   ...        ...     ...     ...      ...         ...         ...   \n",
       "274   ...        0.0     0.0     0.0      0.0         1.0         0.0   \n",
       "238   ...        1.0     0.0     0.0      0.0         0.0         1.0   \n",
       "1444  ...        0.0     0.0     0.0      0.0         0.0         1.0   \n",
       "409   ...        1.0     1.0     1.0      0.0         0.0         1.0   \n",
       "444   ...        1.0     0.0     0.0      0.0         0.0         0.0   \n",
       "\n",
       "      GEPAR_S_n  ASP_S_n  TIKL_S_n  TRENT_S_n  \n",
       "1414        1.0      1.0       0.0        0.0  \n",
       "227         1.0      1.0       0.0        0.0  \n",
       "280         0.0      1.0       0.0        0.0  \n",
       "1538        0.0      1.0       0.0        0.0  \n",
       "1418        0.0      0.0       0.0        0.0  \n",
       "...         ...      ...       ...        ...  \n",
       "274         1.0      1.0       0.0        0.0  \n",
       "238         1.0      0.0       0.0        0.0  \n",
       "1444        0.0      0.0       0.0        1.0  \n",
       "409         1.0      1.0       0.0        0.0  \n",
       "444         1.0      1.0       0.0        1.0  \n",
       "\n",
       "[1360 rows x 77 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the continouous columns, so later can join together\n",
    "X_train=X_train.drop(continue_df, axis=1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "037d3b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>SIM_GIPERT</th>\n",
       "      <th>nr_11</th>\n",
       "      <th>nr_01</th>\n",
       "      <th>nr_02</th>\n",
       "      <th>nr_03</th>\n",
       "      <th>nr_04</th>\n",
       "      <th>nr_07</th>\n",
       "      <th>nr_08</th>\n",
       "      <th>np_01</th>\n",
       "      <th>...</th>\n",
       "      <th>FK_STENOK</th>\n",
       "      <th>IBS_POST</th>\n",
       "      <th>GB</th>\n",
       "      <th>DLIT_AG</th>\n",
       "      <th>ZSN_A</th>\n",
       "      <th>ant_im</th>\n",
       "      <th>lat_im</th>\n",
       "      <th>inf_im</th>\n",
       "      <th>post_im</th>\n",
       "      <th>TIME_B_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1360 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SEX  SIM_GIPERT  nr_11  nr_01  nr_02  nr_03  nr_04  nr_07  nr_08  np_01  \\\n",
       "1414    0         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "227     0         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "280     1         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1538    0         0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0   \n",
       "1418    0         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...   ...         ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "274     1         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "238     1         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1444    1         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "409     0         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "444     1         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      ...  FK_STENOK  IBS_POST        GB   DLIT_AG  ZSN_A  ant_im  lat_im  \\\n",
       "1414  ...       0.50       0.5  0.666667  0.857143    0.0    0.00    0.00   \n",
       "227   ...       0.50       1.0  0.666667  0.857143    0.0    0.00    0.00   \n",
       "280   ...       0.00       1.0  0.666667  0.285714    0.0    0.00    0.00   \n",
       "1538  ...       0.75       0.5  0.666667  0.857143    1.0    0.25    0.25   \n",
       "1418  ...       0.50       1.0  0.666667  0.428571    0.0    0.25    0.25   \n",
       "...   ...        ...       ...       ...       ...    ...     ...     ...   \n",
       "274   ...       0.00       1.0  0.666667  0.142857    0.0    0.75    0.25   \n",
       "238   ...       0.50       1.0  0.666667  0.428571    0.0    0.00    0.00   \n",
       "1444  ...       0.00       0.0  0.000000  0.000000    0.0    1.00    0.25   \n",
       "409   ...       0.00       1.0  0.666667  0.285714    0.0    1.00    0.25   \n",
       "444   ...       0.50       0.5  0.000000  0.000000    0.0    0.25    0.25   \n",
       "\n",
       "      inf_im  post_im  TIME_B_S  \n",
       "1414    0.75     0.25     0.750  \n",
       "227     0.75     0.00     0.250  \n",
       "280     0.75     0.00     1.000  \n",
       "1538    0.00     0.00     0.250  \n",
       "1418    0.00     0.00     0.125  \n",
       "...      ...      ...       ...  \n",
       "274     0.00     0.00     0.750  \n",
       "238     0.50     0.00     0.125  \n",
       "1444    0.00     0.00     1.000  \n",
       "409     1.00     0.00     0.250  \n",
       "444     0.00     0.00     0.375  \n",
       "\n",
       "[1360 rows x 98 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put continuous columns back\n",
    "new_X_train=X_train.join(continue_df)\n",
    "new_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fa9ef75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>INF_ANAM</th>\n",
       "      <th>STENOK_AN</th>\n",
       "      <th>FK_STENOK</th>\n",
       "      <th>IBS_POST</th>\n",
       "      <th>GB</th>\n",
       "      <th>SIM_GIPERT</th>\n",
       "      <th>DLIT_AG</th>\n",
       "      <th>ZSN_A</th>\n",
       "      <th>...</th>\n",
       "      <th>LID_KB</th>\n",
       "      <th>NITR_S</th>\n",
       "      <th>LID_S_n</th>\n",
       "      <th>B_BLOK_S_n</th>\n",
       "      <th>ANT_CA_S_n</th>\n",
       "      <th>GEPAR_S_n</th>\n",
       "      <th>ASP_S_n</th>\n",
       "      <th>TIKL_S_n</th>\n",
       "      <th>TRENT_S_n</th>\n",
       "      <th>LET_IS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>51.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>83.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AGE  SEX  INF_ANAM  STENOK_AN  FK_STENOK  IBS_POST   GB  SIM_GIPERT  \\\n",
       "455   50.0    1       0.0        0.0        0.0       2.0  0.0         0.0   \n",
       "1499  64.0    0       0.0        5.0        3.0       2.0  0.0         0.0   \n",
       "1045  61.0    1       1.0        5.0        2.0       1.0  2.0         0.0   \n",
       "187   75.0    0       0.0        6.0        1.0       2.0  2.0         0.0   \n",
       "1472  62.0    0       0.0        6.0        2.0       1.0  3.0         0.0   \n",
       "...    ...  ...       ...        ...        ...       ...  ...         ...   \n",
       "749   51.0    1       0.0        1.0        2.0       1.0  0.0         0.0   \n",
       "207   76.0    0       0.0        1.0        2.0       2.0  2.0         0.0   \n",
       "779   83.0    0       1.0        2.0        2.0       1.0  3.0         0.0   \n",
       "954   76.0    1       0.0        4.0        2.0       2.0  2.0         0.0   \n",
       "1428  76.0    0       1.0        1.0        2.0       1.0  3.0         0.0   \n",
       "\n",
       "      DLIT_AG  ZSN_A  ...  LID_KB  NITR_S  LID_S_n  B_BLOK_S_n  ANT_CA_S_n  \\\n",
       "455       0.0    0.0  ...     1.0     0.0      0.0         0.0         1.0   \n",
       "1499      0.0    0.0  ...     0.0     0.0      1.0         1.0         1.0   \n",
       "1045      6.0    0.0  ...     0.0     0.0      0.0         0.0         1.0   \n",
       "187       7.0    0.0  ...     0.0     0.0      0.0         0.0         1.0   \n",
       "1472      6.0    0.0  ...     0.0     0.0      0.0         0.0         1.0   \n",
       "...       ...    ...  ...     ...     ...      ...         ...         ...   \n",
       "749       0.0    0.0  ...     NaN     0.0      0.0         0.0         1.0   \n",
       "207       7.0    1.0  ...     0.0     0.0      0.0         0.0         1.0   \n",
       "779       NaN    0.0  ...     NaN     0.0      0.0         0.0         1.0   \n",
       "954       NaN    2.0  ...     0.0     0.0      1.0         0.0         0.0   \n",
       "1428      7.0    NaN  ...     0.0     0.0      0.0         0.0         1.0   \n",
       "\n",
       "      GEPAR_S_n  ASP_S_n  TIKL_S_n  TRENT_S_n  LET_IS  \n",
       "455         1.0      1.0       0.0        0.0       0  \n",
       "1499        1.0      1.0       0.0        0.0       1  \n",
       "1045        1.0      1.0       0.0        0.0       0  \n",
       "187         0.0      1.0       0.0        0.0       0  \n",
       "1472        1.0      1.0       0.0        0.0       1  \n",
       "...         ...      ...       ...        ...     ...  \n",
       "749         1.0      1.0       0.0        0.0       0  \n",
       "207         0.0      1.0       0.0        0.0       0  \n",
       "779         0.0      0.0       0.0        1.0       0  \n",
       "954         1.0      0.0       0.0        0.0       0  \n",
       "1428        0.0      1.0       0.0        1.0       1  \n",
       "\n",
       "[340 rows x 99 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data and see how it looks like\n",
    "test = pd.read_csv('test', index_col = 0)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f31c573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 340 entries, 455 to 1428\n",
      "Data columns (total 99 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   AGE            338 non-null    float64\n",
      " 1   SEX            340 non-null    int64  \n",
      " 2   INF_ANAM       340 non-null    float64\n",
      " 3   STENOK_AN      324 non-null    float64\n",
      " 4   FK_STENOK      329 non-null    float64\n",
      " 5   IBS_POST       332 non-null    float64\n",
      " 6   GB             338 non-null    float64\n",
      " 7   SIM_GIPERT     339 non-null    float64\n",
      " 8   DLIT_AG        287 non-null    float64\n",
      " 9   ZSN_A          331 non-null    float64\n",
      " 10  nr_11          337 non-null    float64\n",
      " 11  nr_01          337 non-null    float64\n",
      " 12  nr_02          337 non-null    float64\n",
      " 13  nr_03          337 non-null    float64\n",
      " 14  nr_04          337 non-null    float64\n",
      " 15  nr_07          337 non-null    float64\n",
      " 16  nr_08          337 non-null    float64\n",
      " 17  np_01          336 non-null    float64\n",
      " 18  np_04          336 non-null    float64\n",
      " 19  np_05          336 non-null    float64\n",
      " 20  np_07          336 non-null    float64\n",
      " 21  np_08          336 non-null    float64\n",
      " 22  np_09          336 non-null    float64\n",
      " 23  np_10          336 non-null    float64\n",
      " 24  endocr_01      336 non-null    float64\n",
      " 25  endocr_02      337 non-null    float64\n",
      " 26  endocr_03      337 non-null    float64\n",
      " 27  zab_leg_01     339 non-null    float64\n",
      " 28  zab_leg_02     339 non-null    float64\n",
      " 29  zab_leg_03     339 non-null    float64\n",
      " 30  zab_leg_04     339 non-null    float64\n",
      " 31  zab_leg_06     339 non-null    float64\n",
      " 32  S_AD_ORIT      293 non-null    float64\n",
      " 33  D_AD_ORIT      293 non-null    float64\n",
      " 34  O_L_POST       338 non-null    float64\n",
      " 35  K_SH_POST      337 non-null    float64\n",
      " 36  MP_TP_POST     338 non-null    float64\n",
      " 37  SVT_POST       338 non-null    float64\n",
      " 38  GT_POST        338 non-null    float64\n",
      " 39  FIB_G_POST     338 non-null    float64\n",
      " 40  ant_im         316 non-null    float64\n",
      " 41  lat_im         316 non-null    float64\n",
      " 42  inf_im         318 non-null    float64\n",
      " 43  post_im        321 non-null    float64\n",
      " 44  IM_PG_P        339 non-null    float64\n",
      " 45  ritm_ecg_p_01  314 non-null    float64\n",
      " 46  ritm_ecg_p_02  314 non-null    float64\n",
      " 47  ritm_ecg_p_04  314 non-null    float64\n",
      " 48  ritm_ecg_p_06  314 non-null    float64\n",
      " 49  ritm_ecg_p_07  314 non-null    float64\n",
      " 50  ritm_ecg_p_08  314 non-null    float64\n",
      " 51  n_r_ecg_p_01   319 non-null    float64\n",
      " 52  n_r_ecg_p_02   319 non-null    float64\n",
      " 53  n_r_ecg_p_03   319 non-null    float64\n",
      " 54  n_r_ecg_p_04   319 non-null    float64\n",
      " 55  n_r_ecg_p_05   319 non-null    float64\n",
      " 56  n_r_ecg_p_06   319 non-null    float64\n",
      " 57  n_r_ecg_p_08   319 non-null    float64\n",
      " 58  n_r_ecg_p_09   319 non-null    float64\n",
      " 59  n_r_ecg_p_10   319 non-null    float64\n",
      " 60  n_p_ecg_p_01   319 non-null    float64\n",
      " 61  n_p_ecg_p_03   319 non-null    float64\n",
      " 62  n_p_ecg_p_04   319 non-null    float64\n",
      " 63  n_p_ecg_p_05   319 non-null    float64\n",
      " 64  n_p_ecg_p_06   319 non-null    float64\n",
      " 65  n_p_ecg_p_07   319 non-null    float64\n",
      " 66  n_p_ecg_p_08   319 non-null    float64\n",
      " 67  n_p_ecg_p_09   319 non-null    float64\n",
      " 68  n_p_ecg_p_10   319 non-null    float64\n",
      " 69  n_p_ecg_p_11   319 non-null    float64\n",
      " 70  n_p_ecg_p_12   319 non-null    float64\n",
      " 71  fibr_ter_01    339 non-null    float64\n",
      " 72  fibr_ter_02    339 non-null    float64\n",
      " 73  fibr_ter_03    339 non-null    float64\n",
      " 74  fibr_ter_05    339 non-null    float64\n",
      " 75  fibr_ter_06    339 non-null    float64\n",
      " 76  fibr_ter_07    339 non-null    float64\n",
      " 77  fibr_ter_08    339 non-null    float64\n",
      " 78  GIPO_K         277 non-null    float64\n",
      " 79  K_BLOOD        277 non-null    float64\n",
      " 80  GIPER_NA       276 non-null    float64\n",
      " 81  NA_BLOOD       276 non-null    float64\n",
      " 82  ALT_BLOOD      285 non-null    float64\n",
      " 83  AST_BLOOD      285 non-null    float64\n",
      " 84  L_BLOOD        318 non-null    float64\n",
      " 85  ROE            306 non-null    float64\n",
      " 86  TIME_B_S       314 non-null    float64\n",
      " 87  NA_KB          203 non-null    float64\n",
      " 88  NOT_NA_KB      201 non-null    float64\n",
      " 89  LID_KB         202 non-null    float64\n",
      " 90  NITR_S         336 non-null    float64\n",
      " 91  LID_S_n        336 non-null    float64\n",
      " 92  B_BLOK_S_n     336 non-null    float64\n",
      " 93  ANT_CA_S_n     335 non-null    float64\n",
      " 94  GEPAR_S_n      335 non-null    float64\n",
      " 95  ASP_S_n        335 non-null    float64\n",
      " 96  TIKL_S_n       335 non-null    float64\n",
      " 97  TRENT_S_n      335 non-null    float64\n",
      " 98  LET_IS         340 non-null    int64  \n",
      "dtypes: float64(97), int64(2)\n",
      "memory usage: 265.6 KB\n"
     ]
    }
   ],
   "source": [
    "newtest = test.loc[:, (test.isnull().sum(axis=0) < 1700/2)]\n",
    "newtest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61cf80ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in median for continuous columns\n",
    "newtest.fillna(newtrain[['AGE', 'INF_ANAM', 'STENOK_AN', 'FK_STENOK', 'IBS_POST', 'GB', 'DLIT_AG', 'ZSN_A',\n",
    "                         'S_AD_ORIT', 'D_AD_ORIT', 'ant_im', 'lat_im', 'inf_im', 'post_im', 'K_BLOOD',\n",
    "                         'NA_BLOOD', 'ALT_BLOOD', 'AST_BLOOD', 'L_BLOOD', 'ROE', 'TIME_B_S']].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be3face3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in mode for the rest columns\n",
    "for column in newtest[newtest.columns[~newtest.columns.isin(['AGE', 'INF_ANAM', 'STENOK_AN', 'FK_STENOK', 'IBS_POST', 'GB', 'DLIT_AG', 'ZSN_A',\n",
    "                         'S_AD_ORIT', 'D_AD_ORIT', 'ant_im', 'lat_im', 'inf_im', 'post_im', 'K_BLOOD',\n",
    "                         'NA_BLOOD', 'ALT_BLOOD', 'AST_BLOOD', 'L_BLOOD', 'ROE', 'TIME_B_S'])]]:\n",
    "    newtest[column].fillna(newtest[column].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "290424b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE          0\n",
       "SEX          0\n",
       "INF_ANAM     0\n",
       "STENOK_AN    0\n",
       "FK_STENOK    0\n",
       "            ..\n",
       "GEPAR_S_n    0\n",
       "ASP_S_n      0\n",
       "TIKL_S_n     0\n",
       "TRENT_S_n    0\n",
       "LET_IS       0\n",
       "Length: 99, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtest.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eaae5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X_test and y_test\n",
    "X_test = newtest.loc[:, newtest.columns!='LET_IS']\n",
    "y_test = pd.Series(newtest['LET_IS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21ca350f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>INF_ANAM</th>\n",
       "      <th>STENOK_AN</th>\n",
       "      <th>FK_STENOK</th>\n",
       "      <th>IBS_POST</th>\n",
       "      <th>GB</th>\n",
       "      <th>SIM_GIPERT</th>\n",
       "      <th>DLIT_AG</th>\n",
       "      <th>ZSN_A</th>\n",
       "      <th>...</th>\n",
       "      <th>NOT_NA_KB</th>\n",
       "      <th>LID_KB</th>\n",
       "      <th>NITR_S</th>\n",
       "      <th>LID_S_n</th>\n",
       "      <th>B_BLOK_S_n</th>\n",
       "      <th>ANT_CA_S_n</th>\n",
       "      <th>GEPAR_S_n</th>\n",
       "      <th>ASP_S_n</th>\n",
       "      <th>TIKL_S_n</th>\n",
       "      <th>TRENT_S_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>51.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>83.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AGE  SEX  INF_ANAM  STENOK_AN  FK_STENOK  IBS_POST   GB  SIM_GIPERT  \\\n",
       "455   50.0    1       0.0        0.0        0.0       2.0  0.0         0.0   \n",
       "1499  64.0    0       0.0        5.0        3.0       2.0  0.0         0.0   \n",
       "1045  61.0    1       1.0        5.0        2.0       1.0  2.0         0.0   \n",
       "187   75.0    0       0.0        6.0        1.0       2.0  2.0         0.0   \n",
       "1472  62.0    0       0.0        6.0        2.0       1.0  3.0         0.0   \n",
       "...    ...  ...       ...        ...        ...       ...  ...         ...   \n",
       "749   51.0    1       0.0        1.0        2.0       1.0  0.0         0.0   \n",
       "207   76.0    0       0.0        1.0        2.0       2.0  2.0         0.0   \n",
       "779   83.0    0       1.0        2.0        2.0       1.0  3.0         0.0   \n",
       "954   76.0    1       0.0        4.0        2.0       2.0  2.0         0.0   \n",
       "1428  76.0    0       1.0        1.0        2.0       1.0  3.0         0.0   \n",
       "\n",
       "      DLIT_AG  ZSN_A  ...  NOT_NA_KB  LID_KB  NITR_S  LID_S_n  B_BLOK_S_n  \\\n",
       "455       0.0    0.0  ...        1.0     1.0     0.0      0.0         0.0   \n",
       "1499      0.0    0.0  ...        0.0     0.0     0.0      1.0         1.0   \n",
       "1045      6.0    0.0  ...        1.0     0.0     0.0      0.0         0.0   \n",
       "187       7.0    0.0  ...        1.0     0.0     0.0      0.0         0.0   \n",
       "1472      6.0    0.0  ...        1.0     0.0     0.0      0.0         0.0   \n",
       "...       ...    ...  ...        ...     ...     ...      ...         ...   \n",
       "749       0.0    0.0  ...        1.0     0.0     0.0      0.0         0.0   \n",
       "207       7.0    1.0  ...        0.0     0.0     0.0      0.0         0.0   \n",
       "779       3.0    0.0  ...        1.0     0.0     0.0      0.0         0.0   \n",
       "954       3.0    2.0  ...        1.0     0.0     0.0      1.0         0.0   \n",
       "1428      7.0    0.0  ...        0.0     0.0     0.0      0.0         0.0   \n",
       "\n",
       "      ANT_CA_S_n  GEPAR_S_n  ASP_S_n  TIKL_S_n  TRENT_S_n  \n",
       "455          1.0        1.0      1.0       0.0        0.0  \n",
       "1499         1.0        1.0      1.0       0.0        0.0  \n",
       "1045         1.0        1.0      1.0       0.0        0.0  \n",
       "187          1.0        0.0      1.0       0.0        0.0  \n",
       "1472         1.0        1.0      1.0       0.0        0.0  \n",
       "...          ...        ...      ...       ...        ...  \n",
       "749          1.0        1.0      1.0       0.0        0.0  \n",
       "207          1.0        0.0      1.0       0.0        0.0  \n",
       "779          1.0        0.0      0.0       0.0        1.0  \n",
       "954          0.0        1.0      0.0       0.0        0.0  \n",
       "1428         1.0        0.0      1.0       0.0        1.0  \n",
       "\n",
       "[340 rows x 98 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30b54bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>S_AD_ORIT</th>\n",
       "      <th>D_AD_ORIT</th>\n",
       "      <th>K_BLOOD</th>\n",
       "      <th>NA_BLOOD</th>\n",
       "      <th>ALT_BLOOD</th>\n",
       "      <th>AST_BLOOD</th>\n",
       "      <th>L_BLOOD</th>\n",
       "      <th>ROE</th>\n",
       "      <th>INF_ANAM</th>\n",
       "      <th>...</th>\n",
       "      <th>FK_STENOK</th>\n",
       "      <th>IBS_POST</th>\n",
       "      <th>GB</th>\n",
       "      <th>DLIT_AG</th>\n",
       "      <th>ZSN_A</th>\n",
       "      <th>ant_im</th>\n",
       "      <th>lat_im</th>\n",
       "      <th>inf_im</th>\n",
       "      <th>post_im</th>\n",
       "      <th>TIME_B_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.447811</td>\n",
       "      <td>0.123223</td>\n",
       "      <td>0.158301</td>\n",
       "      <td>0.086331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.372881</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.595960</td>\n",
       "      <td>0.123223</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.316547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>0.530303</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.218855</td>\n",
       "      <td>0.085308</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.194245</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.067340</td>\n",
       "      <td>0.014218</td>\n",
       "      <td>0.204633</td>\n",
       "      <td>0.079137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.014218</td>\n",
       "      <td>0.420849</td>\n",
       "      <td>0.028777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>0.378788</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.085308</td>\n",
       "      <td>0.386100</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.186441</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.195286</td>\n",
       "      <td>0.085308</td>\n",
       "      <td>0.335907</td>\n",
       "      <td>0.280576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.014218</td>\n",
       "      <td>0.181467</td>\n",
       "      <td>0.093525</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.389831</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.117845</td>\n",
       "      <td>0.085308</td>\n",
       "      <td>0.235521</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.447811</td>\n",
       "      <td>0.336493</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.294964</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AGE  S_AD_ORIT  D_AD_ORIT   K_BLOOD  NA_BLOOD  ALT_BLOOD  \\\n",
       "455   0.363636   0.500000   0.421053  0.271186  0.076923   0.447811   \n",
       "1499  0.575758   0.423077   0.368421  0.372881  0.365385   0.595960   \n",
       "1045  0.530303   0.692308   0.473684  0.440678  0.365385   0.218855   \n",
       "187   0.742424   0.692308   0.578947  0.694915  0.346154   0.067340   \n",
       "1472  0.545455   0.769231   0.578947  0.423729  0.403846   0.040404   \n",
       "...        ...        ...        ...       ...       ...        ...   \n",
       "749   0.378788   0.500000   0.421053  0.305085  0.365385   0.090909   \n",
       "207   0.757576   0.538462   0.473684  0.186441  0.384615   0.195286   \n",
       "779   0.863636   0.538462   0.421053  0.305085  0.365385   0.040404   \n",
       "954   0.757576   0.538462   0.368421  0.389831  0.461538   0.117845   \n",
       "1428  0.757576   0.538462   0.421053  0.542373  0.250000   0.447811   \n",
       "\n",
       "      AST_BLOOD   L_BLOOD       ROE  INF_ANAM  ...  FK_STENOK  IBS_POST  \\\n",
       "455    0.123223  0.158301  0.086331  0.000000  ...       0.00       1.0   \n",
       "1499   0.123223  0.243243  0.316547  0.000000  ...       0.75       1.0   \n",
       "1045   0.085308  0.189189  0.194245  0.333333  ...       0.50       0.5   \n",
       "187    0.014218  0.204633  0.079137  0.000000  ...       0.25       1.0   \n",
       "1472   0.014218  0.420849  0.028777  0.000000  ...       0.50       0.5   \n",
       "...         ...       ...       ...       ...  ...        ...       ...   \n",
       "749    0.085308  0.386100  0.014388  0.000000  ...       0.50       0.5   \n",
       "207    0.085308  0.335907  0.280576  0.000000  ...       0.50       1.0   \n",
       "779    0.014218  0.181467  0.093525  0.333333  ...       0.50       0.5   \n",
       "954    0.085308  0.235521  0.014388  0.000000  ...       0.50       1.0   \n",
       "1428   0.336493  0.567568  0.294964  0.333333  ...       0.50       0.5   \n",
       "\n",
       "            GB   DLIT_AG  ZSN_A  ant_im  lat_im  inf_im  post_im  TIME_B_S  \n",
       "455   0.000000  0.000000   0.00    1.00    0.25    0.00      0.0     0.875  \n",
       "1499  0.000000  0.000000   0.00    0.00    0.00    0.50      0.5     0.750  \n",
       "1045  0.666667  0.857143   0.00    0.00    0.00    0.25      0.0     0.125  \n",
       "187   0.666667  1.000000   0.00    0.25    0.25    0.00      0.0     1.000  \n",
       "1472  1.000000  0.857143   0.00    0.00    0.00    1.00      0.5     0.375  \n",
       "...        ...       ...    ...     ...     ...     ...      ...       ...  \n",
       "749   0.000000  0.000000   0.00    0.25    0.25    0.00      0.0     1.000  \n",
       "207   0.666667  1.000000   0.25    1.00    0.25    0.00      0.0     1.000  \n",
       "779   1.000000  0.428571   0.00    0.00    0.00    0.50      0.0     0.125  \n",
       "954   0.666667  0.428571   0.50    0.25    0.25    0.00      0.0     1.000  \n",
       "1428  1.000000  1.000000   0.00    0.00    0.00    0.50      0.0     0.500  \n",
       "\n",
       "[340 rows x 21 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the values of continuous columns in X_test\n",
    "test_continue_df=pd.DataFrame(scalor.transform(X_test[continuous_col].to_numpy()), columns=['AGE', 'S_AD_ORIT', 'D_AD_ORIT', 'K_BLOOD', 'NA_BLOOD',\\\n",
    " 'ALT_BLOOD', 'AST_BLOOD', 'L_BLOOD', 'ROE', 'INF_ANAM', 'STENOK_AN', 'FK_STENOK', 'IBS_POST', 'GB', 'DLIT_AG', 'ZSN_A',\\\n",
    " 'ant_im', 'lat_im', 'inf_im', 'post_im', 'TIME_B_S'], index=X_test.index)\n",
    "test_continue_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "863e6a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>SIM_GIPERT</th>\n",
       "      <th>nr_11</th>\n",
       "      <th>nr_01</th>\n",
       "      <th>nr_02</th>\n",
       "      <th>nr_03</th>\n",
       "      <th>nr_04</th>\n",
       "      <th>nr_07</th>\n",
       "      <th>nr_08</th>\n",
       "      <th>np_01</th>\n",
       "      <th>...</th>\n",
       "      <th>NOT_NA_KB</th>\n",
       "      <th>LID_KB</th>\n",
       "      <th>NITR_S</th>\n",
       "      <th>LID_S_n</th>\n",
       "      <th>B_BLOK_S_n</th>\n",
       "      <th>ANT_CA_S_n</th>\n",
       "      <th>GEPAR_S_n</th>\n",
       "      <th>ASP_S_n</th>\n",
       "      <th>TIKL_S_n</th>\n",
       "      <th>TRENT_S_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SEX  SIM_GIPERT  nr_11  nr_01  nr_02  nr_03  nr_04  nr_07  nr_08  np_01  \\\n",
       "455     1         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1499    0         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1045    1         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "187     0         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1472    0         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...   ...         ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "749     1         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "207     0         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "779     0         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "954     1         0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0   \n",
       "1428    0         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      ...  NOT_NA_KB  LID_KB  NITR_S  LID_S_n  B_BLOK_S_n  ANT_CA_S_n  \\\n",
       "455   ...        1.0     1.0     0.0      0.0         0.0         1.0   \n",
       "1499  ...        0.0     0.0     0.0      1.0         1.0         1.0   \n",
       "1045  ...        1.0     0.0     0.0      0.0         0.0         1.0   \n",
       "187   ...        1.0     0.0     0.0      0.0         0.0         1.0   \n",
       "1472  ...        1.0     0.0     0.0      0.0         0.0         1.0   \n",
       "...   ...        ...     ...     ...      ...         ...         ...   \n",
       "749   ...        1.0     0.0     0.0      0.0         0.0         1.0   \n",
       "207   ...        0.0     0.0     0.0      0.0         0.0         1.0   \n",
       "779   ...        1.0     0.0     0.0      0.0         0.0         1.0   \n",
       "954   ...        1.0     0.0     0.0      1.0         0.0         0.0   \n",
       "1428  ...        0.0     0.0     0.0      0.0         0.0         1.0   \n",
       "\n",
       "      GEPAR_S_n  ASP_S_n  TIKL_S_n  TRENT_S_n  \n",
       "455         1.0      1.0       0.0        0.0  \n",
       "1499        1.0      1.0       0.0        0.0  \n",
       "1045        1.0      1.0       0.0        0.0  \n",
       "187         0.0      1.0       0.0        0.0  \n",
       "1472        1.0      1.0       0.0        0.0  \n",
       "...         ...      ...       ...        ...  \n",
       "749         1.0      1.0       0.0        0.0  \n",
       "207         0.0      1.0       0.0        0.0  \n",
       "779         0.0      0.0       0.0        1.0  \n",
       "954         1.0      0.0       0.0        0.0  \n",
       "1428        0.0      1.0       0.0        1.0  \n",
       "\n",
       "[340 rows x 77 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop continuous columns in X_test, so we can join back later\n",
    "X_test=X_test.drop(continue_df, axis=1)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "099a4912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>SIM_GIPERT</th>\n",
       "      <th>nr_11</th>\n",
       "      <th>nr_01</th>\n",
       "      <th>nr_02</th>\n",
       "      <th>nr_03</th>\n",
       "      <th>nr_04</th>\n",
       "      <th>nr_07</th>\n",
       "      <th>nr_08</th>\n",
       "      <th>np_01</th>\n",
       "      <th>...</th>\n",
       "      <th>FK_STENOK</th>\n",
       "      <th>IBS_POST</th>\n",
       "      <th>GB</th>\n",
       "      <th>DLIT_AG</th>\n",
       "      <th>ZSN_A</th>\n",
       "      <th>ant_im</th>\n",
       "      <th>lat_im</th>\n",
       "      <th>inf_im</th>\n",
       "      <th>post_im</th>\n",
       "      <th>TIME_B_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SEX  SIM_GIPERT  nr_11  nr_01  nr_02  nr_03  nr_04  nr_07  nr_08  np_01  \\\n",
       "455     1         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1499    0         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1045    1         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "187     0         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1472    0         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...   ...         ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "749     1         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "207     0         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "779     0         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "954     1         0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0   \n",
       "1428    0         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      ...  FK_STENOK  IBS_POST        GB   DLIT_AG  ZSN_A  ant_im  lat_im  \\\n",
       "455   ...       0.00       1.0  0.000000  0.000000   0.00    1.00    0.25   \n",
       "1499  ...       0.75       1.0  0.000000  0.000000   0.00    0.00    0.00   \n",
       "1045  ...       0.50       0.5  0.666667  0.857143   0.00    0.00    0.00   \n",
       "187   ...       0.25       1.0  0.666667  1.000000   0.00    0.25    0.25   \n",
       "1472  ...       0.50       0.5  1.000000  0.857143   0.00    0.00    0.00   \n",
       "...   ...        ...       ...       ...       ...    ...     ...     ...   \n",
       "749   ...       0.50       0.5  0.000000  0.000000   0.00    0.25    0.25   \n",
       "207   ...       0.50       1.0  0.666667  1.000000   0.25    1.00    0.25   \n",
       "779   ...       0.50       0.5  1.000000  0.428571   0.00    0.00    0.00   \n",
       "954   ...       0.50       1.0  0.666667  0.428571   0.50    0.25    0.25   \n",
       "1428  ...       0.50       0.5  1.000000  1.000000   0.00    0.00    0.00   \n",
       "\n",
       "      inf_im  post_im  TIME_B_S  \n",
       "455     0.00      0.0     0.875  \n",
       "1499    0.50      0.5     0.750  \n",
       "1045    0.25      0.0     0.125  \n",
       "187     0.00      0.0     1.000  \n",
       "1472    1.00      0.5     0.375  \n",
       "...      ...      ...       ...  \n",
       "749     0.00      0.0     1.000  \n",
       "207     0.00      0.0     1.000  \n",
       "779     0.50      0.0     0.125  \n",
       "954     0.00      0.0     1.000  \n",
       "1428    0.50      0.0     0.500  \n",
       "\n",
       "[340 rows x 98 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join\n",
    "new_X_test=X_test.join(test_continue_df)\n",
    "new_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15eda08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1360, 98)\n",
      "(340, 98)\n",
      "(1360,)\n",
      "(340,)\n"
     ]
    }
   ],
   "source": [
    "#Check the shapes to ensure that we split correctly. \n",
    "print(new_X_train.shape)\n",
    "print(new_X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8632c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "# Since the dirstribution is not normal distribution, we decided to use stratified k fold cross validation.\n",
    "Stratifield_KF = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "print(Stratifield_KF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a217ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MLPClassifier as my FCN model.\n",
    "# max_iter is the maximum number of iterations to end if the algorithm did not converge before max_iter\n",
    "# learning_rate is the choice of learning rate algorithm. 'invscaling' decreases learning rate by inverse scaling exponent. \n",
    "# adaptive decreases learning at constant rate unless learning rate does not change substantially for multiple epochs. \n",
    "# hidden_layer_sizes is the number of neurons in the ith layer. All options have 100 neurons in the first hidden layer, \n",
    "# second and last layer.\n",
    "# activation is the activation function to use at each neuron, with either logistic or relu activation functions. \n",
    "MLPparameters={\n",
    "'max_iter':[5000],\n",
    "'learning_rate': [\"invscaling\", \"adaptive\"],\n",
    "'hidden_layer_sizes': [(100,1), (100,2),(100,3)],\n",
    "'activation': [\"logistic\", \"relu\"]\n",
    "}\n",
    "\n",
    "clf = MLPClassifier(random_state=1)\n",
    "\n",
    "#Setup our base classifier and add it to the RandomizedSearch cross validation model, evaluated using f1 scoring and \n",
    "#cross validated using our stratified KFold cross validation. \n",
    "\n",
    "rand_search = RandomizedSearchCV(clf, param_distributions = MLPparameters, cv = Stratifield_KF, scoring = 'f1', random_state = 111)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e403d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),\n",
       "                   estimator=MLPClassifier(random_state=1),\n",
       "                   param_distributions={'activation': ['logistic', 'relu'],\n",
       "                                        'hidden_layer_sizes': [(100, 1),\n",
       "                                                               (100, 2),\n",
       "                                                               (100, 3)],\n",
       "                                        'learning_rate': ['invscaling',\n",
       "                                                          'adaptive'],\n",
       "                                        'max_iter': [5000]},\n",
       "                   random_state=111, scoring='f1')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the best model using randomized search, fit to our training data. \n",
    "rand_search.fit(new_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "a070cbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.5336251956833021\n",
      "Best Hyperparameters: {'max_iter': 5000, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (100, 1), 'activation': 'logistic'}\n"
     ]
    }
   ],
   "source": [
    "#Save and print our best parameters and our best f1-score. \n",
    "# The best score is low\n",
    "print('Best Score: %s' % rand_search.best_score_)\n",
    "print('Best Hyperparameters: %s' % rand_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe73af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rand_search.score(new_X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24e6b79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 5000, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (100, 1), 'activation': 'logistic'}\n",
      "0.5336251956833021\n"
     ]
    }
   ],
   "source": [
    "# Save our best parameters and our best f1-score. It's the same thing like I did above.\n",
    "# best_mlp_param = rand_search.best_params_\n",
    "# best_mlp_score = rand_search.best_score_\n",
    "# print(best_mlp_param)\n",
    "# print(best_mlp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c76f3ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87       286\n",
      "           1       0.41      0.67      0.51        54\n",
      "\n",
      "    accuracy                           0.79       340\n",
      "   macro avg       0.67      0.74      0.69       340\n",
      "weighted avg       0.85      0.79      0.81       340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using our best parameters, create a new multilayer perceptron, fit with our training data, \n",
    "# predict class on our testing data, and evaluate performance using the true testing labels. \n",
    "mlp_mod_fin = MLPClassifier(**best_mlp_param)\n",
    "mlp_mod_fin.fit(new_X_train, y_train)\n",
    "mlp_y_pred = mlp_mod_fin.predict(new_X_test)\n",
    "# The multi-layer perception performance on the test dataset. It had an average performance of 0.69 in f1-score.\n",
    "print(classification_report(y_test, mlp_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c658e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set XGBoost classifier. Because it's a binary task, set a binary logistic objective with a logloss evaluation metric.\n",
    "xgb_model = xgb.XGBClassifier(random_state=7, objective='binary:logistic', eval_metric='logloss', use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "078030b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define further possible parameters: max_depth, refers to the maximum depth of the trees for each estimator, default is 3\n",
    "# n_estimators refer to the number of estimators used in the boosting process\n",
    "xgb_param={\n",
    "    'max_depth':[3, 5, 7, 9],\n",
    "    'n_estimators':[50, 100, 150, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1878b851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric='logloss', gamma=None,\n",
       "                                           gpu_id=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           in...\n",
       "                                           max_cat_to_onehot=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           max_leaves=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=7,\n",
       "                                           reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_iter=16,\n",
       "                   param_distributions={'max_depth': [3, 5, 7, 9],\n",
       "                                        'n_estimators': [50, 100, 150, 200]},\n",
       "                   random_state=7, scoring='f1')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the best performing model on our training data using our parameter space, stratified cross validation, and \n",
    "#scored with f1-scoring. \n",
    "xgb_mod = RandomizedSearchCV(xgb_model, xgb_param, cv = Stratifield_KF, \n",
    "                             scoring = \"f1\", n_iter = 16, random_state = 7) \n",
    "xgb_mod.fit(new_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb962772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'max_depth': 7}\n",
      "0.5538312399392173\n"
     ]
    }
   ],
   "source": [
    "#S ave and print the best parameters and best scoring. \n",
    "best_xgb_param = xgb_mod.best_params_\n",
    "best_xgb_score = xgb_mod.best_score_\n",
    "print(best_xgb_param)\n",
    "# The best score in training set of xgboost, which is close to MLPClassifier.\n",
    "print(best_xgb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e46e81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93       286\n",
      "           1       0.64      0.43      0.51        54\n",
      "\n",
      "    accuracy                           0.87       340\n",
      "   macro avg       0.77      0.69      0.72       340\n",
      "weighted avg       0.86      0.87      0.86       340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize new model using our best parameters, fit with our training data, predict class label using the X testing data, and \n",
    "# evaluate performance using our true y labels. \n",
    "xgb_mod_fin = xgb.XGBClassifier(**best_xgb_param)\n",
    "xgb_mod_fin.fit(new_X_train, y_train)\n",
    "xgb_y_pred = xgb_mod_fin.predict(new_X_test)\n",
    "# The xgboost performance on the test dataset. It had an average performance of 0.72 in f1-score, which is higher than MLP.\n",
    "print(classification_report(y_test, xgb_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad8d5c5",
   "metadata": {},
   "source": [
    "### Compared with MLP and XGBoost\n",
    "#### When predicting of the testing dataset, XGBoost has a higher average performance of 0.77 in precision, 0.72 in f1-score. On the other hand, MLP has 0.67 in precision, 0.69 in f1-score. However, MLP has a higher performance of 0.74 in recall compared with XGBoost (0.69).\n",
    "\n",
    "#### In MLP, the training dataset achieved a best score around 0.53, and the model predicted on the testing data is 0.69. In XGBoost, the training dataset achieved a best score around 0.55, and the model predicted on the testing data is 0.72. Both models may underfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3f0dcc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to use Keras SequentialAPI, the task is binary\n",
    "def build_model(activation = \"relu\", metrics = [\"accuracy\"], loss = \"binary_crossentropy\", optimizer = \"adam\", input_shape = [98]):\n",
    "    model = models.Sequential([ \n",
    "        layers.Dense(16, activation=activation, input_shape=input_shape, name = \"hidden_1\"),\n",
    "        layers.Dense(16, activation=activation, name = \"hidden_2\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\", name = \"output\")\n",
    "    ])\n",
    "\n",
    "    model.compile(metrics=metrics, \n",
    "                  loss=loss,\n",
    "                  optimizer=optimizer)\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b07b598e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_1 (Dense)            (None, 16)                1584      \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,873\n",
      "Trainable params: 1,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display the summary of the model. \n",
    "print(build_model().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "92ca2474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.wrappers.scikit_learn.KerasClassifier object at 0x0000021D5AB8F5C0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jin\\anaconda3\\envs\\data-science\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# For using random research later, use KerasClassifier to wrap the above network\n",
    "keras_class = keras.wrappers.scikit_learn.KerasClassifier(build_model)\n",
    "print(keras_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "55c3e356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Epoch 1/5\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.4939 - accuracy: 0.8189 - val_loss: 0.4085 - val_accuracy: 0.8412\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3725 - accuracy: 0.8465 - val_loss: 0.3627 - val_accuracy: 0.8765\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3162 - accuracy: 0.8778 - val_loss: 0.3366 - val_accuracy: 0.8706\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2931 - accuracy: 0.8860 - val_loss: 0.3405 - val_accuracy: 0.8765\n",
      "Epoch 5/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2713 - accuracy: 0.8943 - val_loss: 0.3462 - val_accuracy: 0.8706\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.3222 - accuracy: 0.8750\n",
      "[CV] END .............................batch_size=5, epochs=5; total time=   2.5s\n",
      "Epoch 1/5\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.4567 - accuracy: 0.8208 - val_loss: 0.3834 - val_accuracy: 0.8412\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3572 - accuracy: 0.8410 - val_loss: 0.3487 - val_accuracy: 0.8412\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3117 - accuracy: 0.8713 - val_loss: 0.3377 - val_accuracy: 0.8588\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2822 - accuracy: 0.8824 - val_loss: 0.3404 - val_accuracy: 0.8676\n",
      "Epoch 5/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2646 - accuracy: 0.8897 - val_loss: 0.3568 - val_accuracy: 0.8471\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8493\n",
      "[CV] END .............................batch_size=5, epochs=5; total time=   2.1s\n",
      "Epoch 1/5\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.4742 - accuracy: 0.7923 - val_loss: 0.3927 - val_accuracy: 0.8412\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3674 - accuracy: 0.8456 - val_loss: 0.3779 - val_accuracy: 0.8588\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3230 - accuracy: 0.8603 - val_loss: 0.3732 - val_accuracy: 0.8441\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2899 - accuracy: 0.8796 - val_loss: 0.3442 - val_accuracy: 0.8706\n",
      "Epoch 5/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2678 - accuracy: 0.8925 - val_loss: 0.3535 - val_accuracy: 0.8618\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.3237 - accuracy: 0.8860\n",
      "[CV] END .............................batch_size=5, epochs=5; total time=   2.1s\n",
      "Epoch 1/5\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.4961 - accuracy: 0.7932 - val_loss: 0.4122 - val_accuracy: 0.8412\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3646 - accuracy: 0.8456 - val_loss: 0.3526 - val_accuracy: 0.8588\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3097 - accuracy: 0.8750 - val_loss: 0.3423 - val_accuracy: 0.8765\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2806 - accuracy: 0.8961 - val_loss: 0.3391 - val_accuracy: 0.8765\n",
      "Epoch 5/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2631 - accuracy: 0.8989 - val_loss: 0.3519 - val_accuracy: 0.8676\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.3185 - accuracy: 0.8676\n",
      "[CV] END .............................batch_size=5, epochs=5; total time=   2.4s\n",
      "Epoch 1/5\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.4329 - accuracy: 0.8392 - val_loss: 0.3862 - val_accuracy: 0.8412\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3644 - accuracy: 0.8465 - val_loss: 0.3500 - val_accuracy: 0.8559\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3209 - accuracy: 0.8713 - val_loss: 0.3334 - val_accuracy: 0.8853\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2928 - accuracy: 0.8869 - val_loss: 0.3436 - val_accuracy: 0.8647\n",
      "Epoch 5/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2830 - accuracy: 0.8897 - val_loss: 0.3414 - val_accuracy: 0.8618\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.2763 - accuracy: 0.8750\n",
      "[CV] END .............................batch_size=5, epochs=5; total time=   1.9s\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.4846 - accuracy: 0.8079 - val_loss: 0.4113 - val_accuracy: 0.8412\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3853 - accuracy: 0.8401 - val_loss: 0.3638 - val_accuracy: 0.8588\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3248 - accuracy: 0.8704 - val_loss: 0.3323 - val_accuracy: 0.8618\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2972 - accuracy: 0.8833 - val_loss: 0.3366 - val_accuracy: 0.8706\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2726 - accuracy: 0.8888 - val_loss: 0.3406 - val_accuracy: 0.8618\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2630 - accuracy: 0.8879 - val_loss: 0.3343 - val_accuracy: 0.8735\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2536 - accuracy: 0.8961 - val_loss: 0.3401 - val_accuracy: 0.8647\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.8971 - val_loss: 0.3474 - val_accuracy: 0.8529\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2384 - accuracy: 0.8998 - val_loss: 0.3536 - val_accuracy: 0.8471\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2360 - accuracy: 0.9035 - val_loss: 0.3514 - val_accuracy: 0.8559\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.3065 - accuracy: 0.8897\n",
      "[CV] END ............................batch_size=5, epochs=10; total time=   3.4s\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.4600 - accuracy: 0.8254 - val_loss: 0.3984 - val_accuracy: 0.8412\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8493 - val_loss: 0.3538 - val_accuracy: 0.8647\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3069 - accuracy: 0.8741 - val_loss: 0.3343 - val_accuracy: 0.8618\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2780 - accuracy: 0.8888 - val_loss: 0.3323 - val_accuracy: 0.8588\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2599 - accuracy: 0.8943 - val_loss: 0.3491 - val_accuracy: 0.8412\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2522 - accuracy: 0.9007 - val_loss: 0.3494 - val_accuracy: 0.8529\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2403 - accuracy: 0.9035 - val_loss: 0.3538 - val_accuracy: 0.8618\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2286 - accuracy: 0.9118 - val_loss: 0.3523 - val_accuracy: 0.8529\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2176 - accuracy: 0.9062 - val_loss: 0.3679 - val_accuracy: 0.8441\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2088 - accuracy: 0.9191 - val_loss: 0.3708 - val_accuracy: 0.8559\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8860\n",
      "[CV] END ............................batch_size=5, epochs=10; total time=   3.4s\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.4412 - accuracy: 0.8355 - val_loss: 0.3932 - val_accuracy: 0.8412\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3706 - accuracy: 0.8419 - val_loss: 0.3813 - val_accuracy: 0.8559\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8603 - val_loss: 0.3726 - val_accuracy: 0.8647\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2923 - accuracy: 0.8851 - val_loss: 0.3514 - val_accuracy: 0.8618\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2683 - accuracy: 0.8961 - val_loss: 0.3563 - val_accuracy: 0.8588\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2584 - accuracy: 0.8989 - val_loss: 0.3632 - val_accuracy: 0.8529\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2435 - accuracy: 0.9026 - val_loss: 0.3719 - val_accuracy: 0.8500\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2371 - accuracy: 0.8998 - val_loss: 0.3775 - val_accuracy: 0.8441\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2293 - accuracy: 0.9118 - val_loss: 0.3905 - val_accuracy: 0.8412\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2211 - accuracy: 0.9182 - val_loss: 0.3935 - val_accuracy: 0.8382\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8787\n",
      "[CV] END ............................batch_size=5, epochs=10; total time=   3.3s\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.4777 - accuracy: 0.8199 - val_loss: 0.4005 - val_accuracy: 0.8412\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3638 - accuracy: 0.8456 - val_loss: 0.3524 - val_accuracy: 0.8559\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3200 - accuracy: 0.8695 - val_loss: 0.3398 - val_accuracy: 0.8618\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2936 - accuracy: 0.8934 - val_loss: 0.3364 - val_accuracy: 0.8500\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2733 - accuracy: 0.8952 - val_loss: 0.3422 - val_accuracy: 0.8412\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2582 - accuracy: 0.8971 - val_loss: 0.3431 - val_accuracy: 0.8500\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.9017 - val_loss: 0.3549 - val_accuracy: 0.8353\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2370 - accuracy: 0.9062 - val_loss: 0.3565 - val_accuracy: 0.8559\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2299 - accuracy: 0.9072 - val_loss: 0.3689 - val_accuracy: 0.8588\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2266 - accuracy: 0.9044 - val_loss: 0.3601 - val_accuracy: 0.8324\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.3369 - accuracy: 0.8456\n",
      "[CV] END ............................batch_size=5, epochs=10; total time=   3.4s\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.4510 - accuracy: 0.8355 - val_loss: 0.3875 - val_accuracy: 0.8412\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3594 - accuracy: 0.8493 - val_loss: 0.3431 - val_accuracy: 0.8676\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3153 - accuracy: 0.8750 - val_loss: 0.3273 - val_accuracy: 0.8706\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2869 - accuracy: 0.8971 - val_loss: 0.3375 - val_accuracy: 0.8647\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2757 - accuracy: 0.8925 - val_loss: 0.3364 - val_accuracy: 0.8559\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2630 - accuracy: 0.8971 - val_loss: 0.3496 - val_accuracy: 0.8471\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2540 - accuracy: 0.9044 - val_loss: 0.3680 - val_accuracy: 0.8441\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.9081 - val_loss: 0.3600 - val_accuracy: 0.8471\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2430 - accuracy: 0.9099 - val_loss: 0.3713 - val_accuracy: 0.8412\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2291 - accuracy: 0.9154 - val_loss: 0.3670 - val_accuracy: 0.8588\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.2817 - accuracy: 0.8787\n",
      "[CV] END ............................batch_size=5, epochs=10; total time=   3.3s\n",
      "Epoch 1/5\n",
      "109/109 [==============================] - 1s 2ms/step - loss: 0.5176 - accuracy: 0.8051 - val_loss: 0.4211 - val_accuracy: 0.8412\n",
      "Epoch 2/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.4071 - accuracy: 0.8419 - val_loss: 0.3846 - val_accuracy: 0.8471\n",
      "Epoch 3/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3581 - accuracy: 0.8511 - val_loss: 0.3541 - val_accuracy: 0.8529\n",
      "Epoch 4/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3256 - accuracy: 0.8640 - val_loss: 0.3456 - val_accuracy: 0.8618\n",
      "Epoch 5/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2997 - accuracy: 0.8860 - val_loss: 0.3379 - val_accuracy: 0.8706\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3100 - accuracy: 0.8676\n",
      "[CV] END ............................batch_size=10, epochs=5; total time=   1.3s\n",
      "Epoch 1/5\n",
      "109/109 [==============================] - 1s 3ms/step - loss: 0.4481 - accuracy: 0.8401 - val_loss: 0.3917 - val_accuracy: 0.8412\n",
      "Epoch 2/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3768 - accuracy: 0.8401 - val_loss: 0.3639 - val_accuracy: 0.8412\n",
      "Epoch 3/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8456 - val_loss: 0.3387 - val_accuracy: 0.8500\n",
      "Epoch 4/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8631 - val_loss: 0.3348 - val_accuracy: 0.8676\n",
      "Epoch 5/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2886 - accuracy: 0.8814 - val_loss: 0.3291 - val_accuracy: 0.8647\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8713\n",
      "[CV] END ............................batch_size=10, epochs=5; total time=   1.4s\n",
      "Epoch 1/5\n",
      "109/109 [==============================] - 1s 2ms/step - loss: 0.4961 - accuracy: 0.8189 - val_loss: 0.3999 - val_accuracy: 0.8412\n",
      "Epoch 2/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3926 - accuracy: 0.8410 - val_loss: 0.3689 - val_accuracy: 0.8588\n",
      "Epoch 3/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8493 - val_loss: 0.3400 - val_accuracy: 0.8853\n",
      "Epoch 4/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3164 - accuracy: 0.8713 - val_loss: 0.3273 - val_accuracy: 0.8765\n",
      "Epoch 5/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2937 - accuracy: 0.8814 - val_loss: 0.3235 - val_accuracy: 0.8824\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3096 - accuracy: 0.8934\n",
      "[CV] END ............................batch_size=10, epochs=5; total time=   1.5s\n",
      "Epoch 1/5\n",
      "109/109 [==============================] - 1s 2ms/step - loss: 0.5992 - accuracy: 0.7031 - val_loss: 0.4403 - val_accuracy: 0.8441\n",
      "Epoch 2/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.4117 - accuracy: 0.8410 - val_loss: 0.3795 - val_accuracy: 0.8471\n",
      "Epoch 3/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3574 - accuracy: 0.8594 - val_loss: 0.3423 - val_accuracy: 0.8588\n",
      "Epoch 4/5\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8704 - val_loss: 0.3304 - val_accuracy: 0.8765\n",
      "Epoch 5/5\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.8851 - val_loss: 0.3378 - val_accuracy: 0.8735\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3234 - accuracy: 0.8640\n",
      "[CV] END ............................batch_size=10, epochs=5; total time=   1.4s\n",
      "Epoch 1/5\n",
      "109/109 [==============================] - 1s 2ms/step - loss: 0.4759 - accuracy: 0.8401 - val_loss: 0.4081 - val_accuracy: 0.8412\n",
      "Epoch 2/5\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8410 - val_loss: 0.3697 - val_accuracy: 0.8441\n",
      "Epoch 3/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3460 - accuracy: 0.8502 - val_loss: 0.3345 - val_accuracy: 0.8529\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3072 - accuracy: 0.8768 - val_loss: 0.3249 - val_accuracy: 0.8765\n",
      "Epoch 5/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2869 - accuracy: 0.8906 - val_loss: 0.3291 - val_accuracy: 0.8676\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2885 - accuracy: 0.8713\n",
      "[CV] END ............................batch_size=10, epochs=5; total time=   1.4s\n",
      "Epoch 1/10\n",
      "109/109 [==============================] - 1s 2ms/step - loss: 0.4737 - accuracy: 0.8382 - val_loss: 0.4068 - val_accuracy: 0.8412\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3811 - accuracy: 0.8401 - val_loss: 0.3695 - val_accuracy: 0.8441\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8548 - val_loss: 0.3426 - val_accuracy: 0.8500\n",
      "Epoch 4/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3091 - accuracy: 0.8713 - val_loss: 0.3324 - val_accuracy: 0.8676\n",
      "Epoch 5/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2860 - accuracy: 0.8860 - val_loss: 0.3300 - val_accuracy: 0.8618\n",
      "Epoch 6/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2710 - accuracy: 0.8888 - val_loss: 0.3334 - val_accuracy: 0.8676\n",
      "Epoch 7/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2604 - accuracy: 0.8888 - val_loss: 0.3405 - val_accuracy: 0.8735\n",
      "Epoch 8/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2519 - accuracy: 0.8980 - val_loss: 0.3467 - val_accuracy: 0.8588\n",
      "Epoch 9/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.9035 - val_loss: 0.3549 - val_accuracy: 0.8529\n",
      "Epoch 10/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2431 - accuracy: 0.9081 - val_loss: 0.3539 - val_accuracy: 0.8676\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2983 - accuracy: 0.8713\n",
      "[CV] END ...........................batch_size=10, epochs=10; total time=   2.0s\n",
      "Epoch 1/10\n",
      "109/109 [==============================] - 1s 2ms/step - loss: 0.4712 - accuracy: 0.8364 - val_loss: 0.4008 - val_accuracy: 0.8412\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3925 - accuracy: 0.8401 - val_loss: 0.3673 - val_accuracy: 0.8471\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3484 - accuracy: 0.8511 - val_loss: 0.3396 - val_accuracy: 0.8647\n",
      "Epoch 4/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3113 - accuracy: 0.8649 - val_loss: 0.3375 - val_accuracy: 0.8794\n",
      "Epoch 5/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2865 - accuracy: 0.8833 - val_loss: 0.3306 - val_accuracy: 0.8765\n",
      "Epoch 6/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2655 - accuracy: 0.8915 - val_loss: 0.3374 - val_accuracy: 0.8706\n",
      "Epoch 7/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2528 - accuracy: 0.9035 - val_loss: 0.3459 - val_accuracy: 0.8559\n",
      "Epoch 8/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2405 - accuracy: 0.9053 - val_loss: 0.3534 - val_accuracy: 0.8500\n",
      "Epoch 9/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2330 - accuracy: 0.9081 - val_loss: 0.3602 - val_accuracy: 0.8529\n",
      "Epoch 10/10\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9127 - val_loss: 0.3683 - val_accuracy: 0.8588\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8787\n",
      "[CV] END ...........................batch_size=10, epochs=10; total time=   2.1s\n",
      "Epoch 1/10\n",
      "109/109 [==============================] - 1s 2ms/step - loss: 0.5271 - accuracy: 0.7583 - val_loss: 0.4159 - val_accuracy: 0.8412\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.4080 - accuracy: 0.8419 - val_loss: 0.3876 - val_accuracy: 0.8500\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3694 - accuracy: 0.8529 - val_loss: 0.3622 - val_accuracy: 0.8676\n",
      "Epoch 4/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8695 - val_loss: 0.3422 - val_accuracy: 0.8735\n",
      "Epoch 5/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3021 - accuracy: 0.8787 - val_loss: 0.3335 - val_accuracy: 0.8676\n",
      "Epoch 6/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2842 - accuracy: 0.8869 - val_loss: 0.3386 - val_accuracy: 0.8676\n",
      "Epoch 7/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2707 - accuracy: 0.8971 - val_loss: 0.3383 - val_accuracy: 0.8647\n",
      "Epoch 8/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2586 - accuracy: 0.8925 - val_loss: 0.3491 - val_accuracy: 0.8618\n",
      "Epoch 9/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2507 - accuracy: 0.8971 - val_loss: 0.3591 - val_accuracy: 0.8441\n",
      "Epoch 10/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2409 - accuracy: 0.9017 - val_loss: 0.3569 - val_accuracy: 0.8618\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3182 - accuracy: 0.8750\n",
      "[CV] END ...........................batch_size=10, epochs=10; total time=   2.1s\n",
      "Epoch 1/10\n",
      "109/109 [==============================] - 1s 3ms/step - loss: 0.4956 - accuracy: 0.8189 - val_loss: 0.3908 - val_accuracy: 0.8412\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8483 - val_loss: 0.3513 - val_accuracy: 0.8559\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3245 - accuracy: 0.8658 - val_loss: 0.3333 - val_accuracy: 0.8706\n",
      "Epoch 4/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2917 - accuracy: 0.8906 - val_loss: 0.3337 - val_accuracy: 0.8676\n",
      "Epoch 5/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2728 - accuracy: 0.8925 - val_loss: 0.3416 - val_accuracy: 0.8618\n",
      "Epoch 6/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2585 - accuracy: 0.8971 - val_loss: 0.3443 - val_accuracy: 0.8647\n",
      "Epoch 7/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.9062 - val_loss: 0.3681 - val_accuracy: 0.8412\n",
      "Epoch 8/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 0.9035 - val_loss: 0.3502 - val_accuracy: 0.8588\n",
      "Epoch 9/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2288 - accuracy: 0.9118 - val_loss: 0.3613 - val_accuracy: 0.8618\n",
      "Epoch 10/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.9072 - val_loss: 0.3666 - val_accuracy: 0.8500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8566\n",
      "[CV] END ...........................batch_size=10, epochs=10; total time=   2.1s\n",
      "Epoch 1/10\n",
      "109/109 [==============================] - 1s 2ms/step - loss: 0.5139 - accuracy: 0.7794 - val_loss: 0.4161 - val_accuracy: 0.8412\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3970 - accuracy: 0.8410 - val_loss: 0.3809 - val_accuracy: 0.8412\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3579 - accuracy: 0.8428 - val_loss: 0.3525 - val_accuracy: 0.8441\n",
      "Epoch 4/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3243 - accuracy: 0.8667 - val_loss: 0.3393 - val_accuracy: 0.8735\n",
      "Epoch 5/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3031 - accuracy: 0.8805 - val_loss: 0.3367 - val_accuracy: 0.8735\n",
      "Epoch 6/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2875 - accuracy: 0.8814 - val_loss: 0.3439 - val_accuracy: 0.8618\n",
      "Epoch 7/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2789 - accuracy: 0.8888 - val_loss: 0.3415 - val_accuracy: 0.8647\n",
      "Epoch 8/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2709 - accuracy: 0.8934 - val_loss: 0.3417 - val_accuracy: 0.8676\n",
      "Epoch 9/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2686 - accuracy: 0.8952 - val_loss: 0.3466 - val_accuracy: 0.8500\n",
      "Epoch 10/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2592 - accuracy: 0.8971 - val_loss: 0.3604 - val_accuracy: 0.8647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2792 - accuracy: 0.8897\n",
      "[CV] END ...........................batch_size=10, epochs=10; total time=   2.1s\n",
      "Epoch 1/5\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.7812 - accuracy: 0.1801 - val_loss: 0.7239 - val_accuracy: 0.2676\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6966 - accuracy: 0.4789 - val_loss: 0.6640 - val_accuracy: 0.7882\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6442 - accuracy: 0.8226 - val_loss: 0.6175 - val_accuracy: 0.8412\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.8401 - val_loss: 0.5585 - val_accuracy: 0.8412\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.8401 - val_loss: 0.4918 - val_accuracy: 0.8412\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.8419\n",
      "[CV] END ...........................batch_size=100, epochs=5; total time=   0.7s\n",
      "Epoch 1/5\n",
      "11/11 [==============================] - 1s 14ms/step - loss: 0.5977 - accuracy: 0.7978 - val_loss: 0.5538 - val_accuracy: 0.8412\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.8419 - val_loss: 0.4754 - val_accuracy: 0.8412\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.8401 - val_loss: 0.4253 - val_accuracy: 0.8412\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8401 - val_loss: 0.4075 - val_accuracy: 0.8412\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8401 - val_loss: 0.4002 - val_accuracy: 0.8412\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8419\n",
      "[CV] END ...........................batch_size=100, epochs=5; total time=   0.9s\n",
      "Epoch 1/5\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.5943 - accuracy: 0.8143 - val_loss: 0.5448 - val_accuracy: 0.8412\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.8401 - val_loss: 0.4837 - val_accuracy: 0.8412\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.8401 - val_loss: 0.4415 - val_accuracy: 0.8412\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.8401 - val_loss: 0.4197 - val_accuracy: 0.8412\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.8401 - val_loss: 0.4102 - val_accuracy: 0.8412\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8419\n",
      "[CV] END ...........................batch_size=100, epochs=5; total time=   0.7s\n",
      "Epoch 1/5\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.7106 - accuracy: 0.4752 - val_loss: 0.6614 - val_accuracy: 0.7265\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.8015 - val_loss: 0.5946 - val_accuracy: 0.8412\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5611 - accuracy: 0.8428 - val_loss: 0.5243 - val_accuracy: 0.8412\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.8401 - val_loss: 0.4662 - val_accuracy: 0.8412\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.8410 - val_loss: 0.4341 - val_accuracy: 0.8412\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.8382\n",
      "[CV] END ...........................batch_size=100, epochs=5; total time=   0.7s\n",
      "Epoch 1/5\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.7508 - accuracy: 0.3153 - val_loss: 0.6721 - val_accuracy: 0.6618\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6300 - accuracy: 0.7767 - val_loss: 0.5767 - val_accuracy: 0.8324\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5481 - accuracy: 0.8419 - val_loss: 0.5073 - val_accuracy: 0.8412\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.8410 - val_loss: 0.4594 - val_accuracy: 0.8412\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.8410 - val_loss: 0.4322 - val_accuracy: 0.8412\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8382\n",
      "[CV] END ...........................batch_size=100, epochs=5; total time=   0.7s\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.7180 - accuracy: 0.3373 - val_loss: 0.6787 - val_accuracy: 0.6912\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6554 - accuracy: 0.7904 - val_loss: 0.6215 - val_accuracy: 0.8412\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6007 - accuracy: 0.8392 - val_loss: 0.5665 - val_accuracy: 0.8412\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.8401 - val_loss: 0.5079 - val_accuracy: 0.8412\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.8401 - val_loss: 0.4552 - val_accuracy: 0.8412\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.8401 - val_loss: 0.4249 - val_accuracy: 0.8412\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.8401 - val_loss: 0.4122 - val_accuracy: 0.8412\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8401 - val_loss: 0.4044 - val_accuracy: 0.8412\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8401 - val_loss: 0.3967 - val_accuracy: 0.8412\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8401 - val_loss: 0.3887 - val_accuracy: 0.8412\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8419\n",
      "[CV] END ..........................batch_size=100, epochs=10; total time=   0.9s\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7724 - accuracy: 0.2647 - val_loss: 0.6868 - val_accuracy: 0.5324\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.7426 - val_loss: 0.5720 - val_accuracy: 0.8382\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.8392 - val_loss: 0.5004 - val_accuracy: 0.8412\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.8401 - val_loss: 0.4569 - val_accuracy: 0.8412\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.8401 - val_loss: 0.4354 - val_accuracy: 0.8412\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.8401 - val_loss: 0.4245 - val_accuracy: 0.8412\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8401 - val_loss: 0.4169 - val_accuracy: 0.8412\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8401 - val_loss: 0.4098 - val_accuracy: 0.8412\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8401 - val_loss: 0.4017 - val_accuracy: 0.8412\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8410 - val_loss: 0.3930 - val_accuracy: 0.8412\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8419\n",
      "[CV] END ..........................batch_size=100, epochs=10; total time=   0.9s\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.5943 - accuracy: 0.8290 - val_loss: 0.5579 - val_accuracy: 0.8382\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.8419 - val_loss: 0.5004 - val_accuracy: 0.8412\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.8410 - val_loss: 0.4639 - val_accuracy: 0.8412\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8410 - val_loss: 0.4408 - val_accuracy: 0.8412\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8410 - val_loss: 0.4265 - val_accuracy: 0.8412\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.8410 - val_loss: 0.4129 - val_accuracy: 0.8441\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8410 - val_loss: 0.4011 - val_accuracy: 0.8500\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8474 - val_loss: 0.3897 - val_accuracy: 0.8529\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.8548 - val_loss: 0.3788 - val_accuracy: 0.8676\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3516 - accuracy: 0.8621 - val_loss: 0.3686 - val_accuracy: 0.8559\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8640\n",
      "[CV] END ..........................batch_size=100, epochs=10; total time=   0.9s\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6316 - accuracy: 0.7500 - val_loss: 0.5790 - val_accuracy: 0.8294\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.8373 - val_loss: 0.5078 - val_accuracy: 0.8412\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.8419 - val_loss: 0.4608 - val_accuracy: 0.8412\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.8410 - val_loss: 0.4333 - val_accuracy: 0.8412\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.8410 - val_loss: 0.4203 - val_accuracy: 0.8412\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.3144 - accuracy: 0.91 - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8410 - val_loss: 0.4132 - val_accuracy: 0.8412\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8410 - val_loss: 0.4067 - val_accuracy: 0.8412\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8410 - val_loss: 0.3990 - val_accuracy: 0.8412\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3914 - accuracy: 0.8410 - val_loss: 0.3914 - val_accuracy: 0.8412\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3821 - accuracy: 0.8410 - val_loss: 0.3839 - val_accuracy: 0.8412\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8382\n",
      "[CV] END ..........................batch_size=100, epochs=10; total time=   0.9s\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.7671 - accuracy: 0.3116 - val_loss: 0.6699 - val_accuracy: 0.6147\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6168 - accuracy: 0.7812 - val_loss: 0.5606 - val_accuracy: 0.8441\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.8419 - val_loss: 0.4955 - val_accuracy: 0.8412\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.8410 - val_loss: 0.4553 - val_accuracy: 0.8412\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.8410 - val_loss: 0.4345 - val_accuracy: 0.8412\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8410 - val_loss: 0.4254 - val_accuracy: 0.8412\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8410 - val_loss: 0.4169 - val_accuracy: 0.8412\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8410 - val_loss: 0.4087 - val_accuracy: 0.8412\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.8410 - val_loss: 0.3982 - val_accuracy: 0.8412\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3898 - accuracy: 0.8410 - val_loss: 0.3850 - val_accuracy: 0.8412\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8382\n",
      "[CV] END ..........................batch_size=100, epochs=10; total time=   0.9s\n",
      "Epoch 1/10\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.4618 - accuracy: 0.8390 - val_loss: 0.3749 - val_accuracy: 0.8441\n",
      "Epoch 2/10\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.3587 - accuracy: 0.8463 - val_loss: 0.3372 - val_accuracy: 0.8647\n",
      "Epoch 3/10\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.3119 - accuracy: 0.8757 - val_loss: 0.3326 - val_accuracy: 0.8735\n",
      "Epoch 4/10\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.2858 - accuracy: 0.8904 - val_loss: 0.3321 - val_accuracy: 0.8794\n",
      "Epoch 5/10\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.2743 - accuracy: 0.8838 - val_loss: 0.3320 - val_accuracy: 0.8529\n",
      "Epoch 6/10\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.2589 - accuracy: 0.8941 - val_loss: 0.3503 - val_accuracy: 0.8647\n",
      "Epoch 7/10\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.2514 - accuracy: 0.8971 - val_loss: 0.3465 - val_accuracy: 0.8500\n",
      "Epoch 8/10\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.2414 - accuracy: 0.8956 - val_loss: 0.3537 - val_accuracy: 0.8500\n",
      "Epoch 9/10\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.2360 - accuracy: 0.9051 - val_loss: 0.3697 - val_accuracy: 0.8382\n",
      "Epoch 10/10\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.2259 - accuracy: 0.9088 - val_loss: 0.3665 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x0000021D5AB8F5C0>,\n",
       "                   n_iter=6,\n",
       "                   param_distributions={'batch_size': [5, 10, 100],\n",
       "                                        'epochs': [5, 10]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create hyperparameter space\n",
    "param_distribs = {'epochs':[5, 10], 'batch_size': [5, 10, 100]}\n",
    "\n",
    "# Try random research\n",
    "rnd_search_cv = RandomizedSearchCV(keras_class, param_distribs, n_iter=6, cv=Stratifield_KF, verbose=2)\n",
    "\n",
    "#Fit the model using the training data and testing data as validation.\n",
    "rnd_search_cv.fit(new_X_train, y_train, validation_data=(new_X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "f65729d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters: {'epochs': 10, 'batch_size': 10}\n",
      "The best accuracy: 0.8830882430076599\n"
     ]
    }
   ],
   "source": [
    "# The result looks much better!\n",
    "print('The best parameters: {}'.format(rnd_search_cv.best_params_))\n",
    "print('The best accuracy: {}'.format(rnd_search_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "8f9569c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 1ms/step - loss: 0.3553 - accuracy: 0.8706\n",
      "0.8705882430076599\n"
     ]
    }
   ],
   "source": [
    "# The test score looks close to training dataset\n",
    "print(rnd_search_cv.score(new_X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "28c89a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just want to see if using f1 score and compare with machine learning result before\n",
    "rnd_search_cv2 = RandomizedSearchCV(keras_class, param_distribs, n_iter=6, cv = Stratifield_KF, verbose=2, scoring = 'f1', random_state = 111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "33e3122a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Epoch 1/5\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.4584 - accuracy: 0.8327 - val_loss: 0.3914 - val_accuracy: 0.8412\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3557 - accuracy: 0.8511 - val_loss: 0.3519 - val_accuracy: 0.8647\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3096 - accuracy: 0.8805 - val_loss: 0.3347 - val_accuracy: 0.8647\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2915 - accuracy: 0.8869 - val_loss: 0.3359 - val_accuracy: 0.8676\n",
      "Epoch 5/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2681 - accuracy: 0.8971 - val_loss: 0.3525 - val_accuracy: 0.8647\n",
      "[CV] END .............................batch_size=5, epochs=5; total time=   1.9s\n",
      "Epoch 1/5\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.4805 - accuracy: 0.8189 - val_loss: 0.4045 - val_accuracy: 0.8412\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3693 - accuracy: 0.8474 - val_loss: 0.3588 - val_accuracy: 0.8441\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3131 - accuracy: 0.8704 - val_loss: 0.3402 - val_accuracy: 0.8706\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2805 - accuracy: 0.8906 - val_loss: 0.3426 - val_accuracy: 0.8794\n",
      "Epoch 5/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2597 - accuracy: 0.8915 - val_loss: 0.3584 - val_accuracy: 0.8647\n",
      "[CV] END .............................batch_size=5, epochs=5; total time=   1.9s\n",
      "Epoch 1/5\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.4300 - accuracy: 0.8401 - val_loss: 0.3943 - val_accuracy: 0.8412\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3607 - accuracy: 0.8438 - val_loss: 0.3560 - val_accuracy: 0.8559\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3114 - accuracy: 0.8649 - val_loss: 0.3566 - val_accuracy: 0.8647\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2812 - accuracy: 0.8879 - val_loss: 0.3420 - val_accuracy: 0.8706\n",
      "Epoch 5/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2595 - accuracy: 0.8943 - val_loss: 0.3501 - val_accuracy: 0.8676\n",
      "[CV] END .............................batch_size=5, epochs=5; total time=   1.9s\n",
      "Epoch 1/5\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.4746 - accuracy: 0.7932 - val_loss: 0.4033 - val_accuracy: 0.8441\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.8585 - val_loss: 0.3525 - val_accuracy: 0.8588\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3001 - accuracy: 0.8814 - val_loss: 0.3532 - val_accuracy: 0.8618\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2737 - accuracy: 0.8989 - val_loss: 0.3554 - val_accuracy: 0.8706\n",
      "Epoch 5/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2576 - accuracy: 0.9017 - val_loss: 0.3703 - val_accuracy: 0.8441\n",
      "[CV] END .............................batch_size=5, epochs=5; total time=   2.0s\n",
      "Epoch 1/5\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.4288 - accuracy: 0.8392 - val_loss: 0.3572 - val_accuracy: 0.8500\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3443 - accuracy: 0.8594 - val_loss: 0.3271 - val_accuracy: 0.8618\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3089 - accuracy: 0.8768 - val_loss: 0.3166 - val_accuracy: 0.8794\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2839 - accuracy: 0.8888 - val_loss: 0.3280 - val_accuracy: 0.8676\n",
      "Epoch 5/5\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2744 - accuracy: 0.8888 - val_loss: 0.3289 - val_accuracy: 0.8588\n",
      "[CV] END .............................batch_size=5, epochs=5; total time=   2.0s\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.4549 - accuracy: 0.8327 - val_loss: 0.3811 - val_accuracy: 0.8471\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.8631 - val_loss: 0.3455 - val_accuracy: 0.8735\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3001 - accuracy: 0.8888 - val_loss: 0.3414 - val_accuracy: 0.8735\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2874 - accuracy: 0.8915 - val_loss: 0.3451 - val_accuracy: 0.8559\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2665 - accuracy: 0.8925 - val_loss: 0.3559 - val_accuracy: 0.8618\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2602 - accuracy: 0.8943 - val_loss: 0.3491 - val_accuracy: 0.8618\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2480 - accuracy: 0.9007 - val_loss: 0.3550 - val_accuracy: 0.8559\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2400 - accuracy: 0.9026 - val_loss: 0.3619 - val_accuracy: 0.8471\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2300 - accuracy: 0.9136 - val_loss: 0.3721 - val_accuracy: 0.8412\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2250 - accuracy: 0.9191 - val_loss: 0.3700 - val_accuracy: 0.8529\n",
      "[CV] END ............................batch_size=5, epochs=10; total time=   3.4s\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.4471 - accuracy: 0.8401 - val_loss: 0.3831 - val_accuracy: 0.8412\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3610 - accuracy: 0.8511 - val_loss: 0.3348 - val_accuracy: 0.8706\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8814 - val_loss: 0.3239 - val_accuracy: 0.8882\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2789 - accuracy: 0.8888 - val_loss: 0.3254 - val_accuracy: 0.8676\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2582 - accuracy: 0.8915 - val_loss: 0.3423 - val_accuracy: 0.8618\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.8952 - val_loss: 0.3435 - val_accuracy: 0.8559\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2359 - accuracy: 0.9035 - val_loss: 0.3536 - val_accuracy: 0.8618\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2229 - accuracy: 0.9062 - val_loss: 0.3595 - val_accuracy: 0.8441\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2108 - accuracy: 0.9154 - val_loss: 0.3732 - val_accuracy: 0.8412\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2006 - accuracy: 0.9219 - val_loss: 0.3888 - val_accuracy: 0.8559\n",
      "[CV] END ............................batch_size=5, epochs=10; total time=   3.2s\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.4889 - accuracy: 0.8107 - val_loss: 0.3993 - val_accuracy: 0.8412\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3888 - accuracy: 0.8428 - val_loss: 0.3793 - val_accuracy: 0.8618\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3415 - accuracy: 0.8603 - val_loss: 0.3691 - val_accuracy: 0.8618\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3060 - accuracy: 0.8805 - val_loss: 0.3410 - val_accuracy: 0.8706\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2811 - accuracy: 0.8888 - val_loss: 0.3439 - val_accuracy: 0.8676\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2692 - accuracy: 0.8879 - val_loss: 0.3519 - val_accuracy: 0.8441\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2534 - accuracy: 0.8906 - val_loss: 0.3595 - val_accuracy: 0.8471\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 0.8971 - val_loss: 0.3620 - val_accuracy: 0.8471\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2395 - accuracy: 0.8998 - val_loss: 0.3760 - val_accuracy: 0.8441\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2320 - accuracy: 0.9127 - val_loss: 0.3748 - val_accuracy: 0.8441\n",
      "[CV] END ............................batch_size=5, epochs=10; total time=   3.3s\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.4840 - accuracy: 0.7776 - val_loss: 0.4026 - val_accuracy: 0.8441\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3552 - accuracy: 0.8483 - val_loss: 0.3392 - val_accuracy: 0.8529\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8750 - val_loss: 0.3261 - val_accuracy: 0.8735\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2841 - accuracy: 0.8943 - val_loss: 0.3305 - val_accuracy: 0.8706\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2671 - accuracy: 0.8961 - val_loss: 0.3441 - val_accuracy: 0.8735\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2553 - accuracy: 0.8952 - val_loss: 0.3467 - val_accuracy: 0.8588\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2434 - accuracy: 0.9053 - val_loss: 0.3612 - val_accuracy: 0.8529\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2356 - accuracy: 0.9118 - val_loss: 0.3631 - val_accuracy: 0.8588\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2287 - accuracy: 0.9136 - val_loss: 0.3788 - val_accuracy: 0.8647\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2257 - accuracy: 0.9127 - val_loss: 0.3868 - val_accuracy: 0.8382\n",
      "[CV] END ............................batch_size=5, epochs=10; total time=   3.3s\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 1s 2ms/step - loss: 0.4837 - accuracy: 0.7868 - val_loss: 0.3840 - val_accuracy: 0.8412\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3576 - accuracy: 0.8474 - val_loss: 0.3428 - val_accuracy: 0.8618\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3101 - accuracy: 0.8704 - val_loss: 0.3264 - val_accuracy: 0.8735\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2857 - accuracy: 0.8888 - val_loss: 0.3420 - val_accuracy: 0.8471\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2773 - accuracy: 0.8915 - val_loss: 0.3380 - val_accuracy: 0.8500\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2660 - accuracy: 0.8943 - val_loss: 0.3517 - val_accuracy: 0.8500\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2573 - accuracy: 0.9026 - val_loss: 0.3687 - val_accuracy: 0.8382\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2484 - accuracy: 0.9053 - val_loss: 0.3575 - val_accuracy: 0.8471\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.9017 - val_loss: 0.3592 - val_accuracy: 0.8412\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.2315 - accuracy: 0.9072 - val_loss: 0.3682 - val_accuracy: 0.8500\n",
      "[CV] END ............................batch_size=5, epochs=10; total time=   3.3s\n",
      "Epoch 1/5\n",
      "109/109 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7914 - val_loss: 0.4128 - val_accuracy: 0.8412\n",
      "Epoch 2/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3920 - accuracy: 0.8401 - val_loss: 0.3846 - val_accuracy: 0.8441\n",
      "Epoch 3/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3540 - accuracy: 0.8520 - val_loss: 0.3512 - val_accuracy: 0.8588\n",
      "Epoch 4/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3240 - accuracy: 0.8676 - val_loss: 0.3401 - val_accuracy: 0.8765\n",
      "Epoch 5/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3005 - accuracy: 0.8842 - val_loss: 0.3334 - val_accuracy: 0.8735\n",
      "[CV] END ............................batch_size=10, epochs=5; total time=   1.2s\n",
      "Epoch 1/5\n",
      "109/109 [==============================] - 1s 2ms/step - loss: 0.5650 - accuracy: 0.7647 - val_loss: 0.4228 - val_accuracy: 0.8412\n",
      "Epoch 2/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.4063 - accuracy: 0.8401 - val_loss: 0.3859 - val_accuracy: 0.8412\n",
      "Epoch 3/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3615 - accuracy: 0.8419 - val_loss: 0.3552 - val_accuracy: 0.8500\n",
      "Epoch 4/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3255 - accuracy: 0.8631 - val_loss: 0.3468 - val_accuracy: 0.8647\n",
      "Epoch 5/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2996 - accuracy: 0.8824 - val_loss: 0.3389 - val_accuracy: 0.8618\n",
      "[CV] END ............................batch_size=10, epochs=5; total time=   1.2s\n",
      "Epoch 1/5\n",
      "109/109 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7482 - val_loss: 0.4087 - val_accuracy: 0.8412\n",
      "Epoch 2/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.4052 - accuracy: 0.8410 - val_loss: 0.3785 - val_accuracy: 0.8471\n",
      "Epoch 3/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3664 - accuracy: 0.8493 - val_loss: 0.3492 - val_accuracy: 0.8676\n",
      "Epoch 4/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8713 - val_loss: 0.3396 - val_accuracy: 0.8618\n",
      "Epoch 5/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3008 - accuracy: 0.8787 - val_loss: 0.3330 - val_accuracy: 0.8618\n",
      "[CV] END ............................batch_size=10, epochs=5; total time=   1.2s\n",
      "Epoch 1/5\n",
      "109/109 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.8070 - val_loss: 0.4220 - val_accuracy: 0.8412\n",
      "Epoch 2/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.4013 - accuracy: 0.8428 - val_loss: 0.3853 - val_accuracy: 0.8441\n",
      "Epoch 3/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3481 - accuracy: 0.8566 - val_loss: 0.3569 - val_accuracy: 0.8647\n",
      "Epoch 4/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3096 - accuracy: 0.8741 - val_loss: 0.3497 - val_accuracy: 0.8618\n",
      "Epoch 5/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2861 - accuracy: 0.8851 - val_loss: 0.3542 - val_accuracy: 0.8529\n",
      "[CV] END ............................batch_size=10, epochs=5; total time=   1.2s\n",
      "Epoch 1/5\n",
      "109/109 [==============================] - 1s 2ms/step - loss: 0.5226 - accuracy: 0.7298 - val_loss: 0.4013 - val_accuracy: 0.8412\n",
      "Epoch 2/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3802 - accuracy: 0.8419 - val_loss: 0.3707 - val_accuracy: 0.8441\n",
      "Epoch 3/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3436 - accuracy: 0.8539 - val_loss: 0.3437 - val_accuracy: 0.8529\n",
      "Epoch 4/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3152 - accuracy: 0.8750 - val_loss: 0.3338 - val_accuracy: 0.8735\n",
      "Epoch 5/5\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2951 - accuracy: 0.8869 - val_loss: 0.3373 - val_accuracy: 0.8735\n",
      "[CV] END ............................batch_size=10, epochs=5; total time=   1.2s\n",
      "Epoch 1/10\n",
      "109/109 [==============================] - 1s 2ms/step - loss: 0.4962 - accuracy: 0.8382 - val_loss: 0.4251 - val_accuracy: 0.8412\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.4058 - accuracy: 0.8401 - val_loss: 0.3918 - val_accuracy: 0.8412\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3638 - accuracy: 0.8483 - val_loss: 0.3526 - val_accuracy: 0.8588\n",
      "Epoch 4/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8649 - val_loss: 0.3352 - val_accuracy: 0.8676\n",
      "Epoch 5/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3012 - accuracy: 0.8842 - val_loss: 0.3258 - val_accuracy: 0.8706\n",
      "Epoch 6/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2850 - accuracy: 0.8869 - val_loss: 0.3253 - val_accuracy: 0.8735\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2723 - accuracy: 0.8888 - val_loss: 0.3272 - val_accuracy: 0.8735\n",
      "Epoch 8/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2624 - accuracy: 0.8925 - val_loss: 0.3282 - val_accuracy: 0.8676\n",
      "Epoch 9/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2540 - accuracy: 0.8925 - val_loss: 0.3328 - val_accuracy: 0.8647\n",
      "Epoch 10/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.9044 - val_loss: 0.3349 - val_accuracy: 0.8588\n",
      "[CV] END ...........................batch_size=10, epochs=10; total time=   2.0s\n",
      "Epoch 1/10\n",
      "109/109 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7472 - val_loss: 0.4122 - val_accuracy: 0.8412\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.4045 - accuracy: 0.8401 - val_loss: 0.3797 - val_accuracy: 0.8441\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8493 - val_loss: 0.3428 - val_accuracy: 0.8588\n",
      "Epoch 4/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3183 - accuracy: 0.8686 - val_loss: 0.3332 - val_accuracy: 0.8588\n",
      "Epoch 5/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2937 - accuracy: 0.8833 - val_loss: 0.3237 - val_accuracy: 0.8647\n",
      "Epoch 6/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2756 - accuracy: 0.8869 - val_loss: 0.3304 - val_accuracy: 0.8676\n",
      "Epoch 7/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2631 - accuracy: 0.8952 - val_loss: 0.3335 - val_accuracy: 0.8618\n",
      "Epoch 8/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2526 - accuracy: 0.8980 - val_loss: 0.3444 - val_accuracy: 0.8647\n",
      "Epoch 9/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.8989 - val_loss: 0.3476 - val_accuracy: 0.8735\n",
      "Epoch 10/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2384 - accuracy: 0.9090 - val_loss: 0.3549 - val_accuracy: 0.8647\n",
      "[CV] END ...........................batch_size=10, epochs=10; total time=   2.0s\n",
      "Epoch 1/10\n",
      "109/109 [==============================] - 1s 2ms/step - loss: 0.4340 - accuracy: 0.8410 - val_loss: 0.4025 - val_accuracy: 0.8441\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3749 - accuracy: 0.8456 - val_loss: 0.3823 - val_accuracy: 0.8706\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3377 - accuracy: 0.8658 - val_loss: 0.3590 - val_accuracy: 0.8794\n",
      "Epoch 4/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3093 - accuracy: 0.8851 - val_loss: 0.3473 - val_accuracy: 0.8647\n",
      "Epoch 5/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2885 - accuracy: 0.8869 - val_loss: 0.3400 - val_accuracy: 0.8735\n",
      "Epoch 6/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2751 - accuracy: 0.8869 - val_loss: 0.3500 - val_accuracy: 0.8618\n",
      "Epoch 7/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2672 - accuracy: 0.8897 - val_loss: 0.3504 - val_accuracy: 0.8618\n",
      "Epoch 8/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2564 - accuracy: 0.8915 - val_loss: 0.3597 - val_accuracy: 0.8559\n",
      "Epoch 9/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2519 - accuracy: 0.8888 - val_loss: 0.3659 - val_accuracy: 0.8529\n",
      "Epoch 10/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2441 - accuracy: 0.8943 - val_loss: 0.3735 - val_accuracy: 0.8618\n",
      "[CV] END ...........................batch_size=10, epochs=10; total time=   2.0s\n",
      "Epoch 1/10\n",
      "109/109 [==============================] - 1s 2ms/step - loss: 0.5533 - accuracy: 0.7381 - val_loss: 0.4239 - val_accuracy: 0.8412\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.4095 - accuracy: 0.8410 - val_loss: 0.3875 - val_accuracy: 0.8412\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3620 - accuracy: 0.8493 - val_loss: 0.3567 - val_accuracy: 0.8559\n",
      "Epoch 4/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3206 - accuracy: 0.8704 - val_loss: 0.3474 - val_accuracy: 0.8765\n",
      "Epoch 5/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2928 - accuracy: 0.8915 - val_loss: 0.3471 - val_accuracy: 0.8735\n",
      "Epoch 6/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2734 - accuracy: 0.8925 - val_loss: 0.3442 - val_accuracy: 0.8735\n",
      "Epoch 7/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2591 - accuracy: 0.8980 - val_loss: 0.3625 - val_accuracy: 0.8471\n",
      "Epoch 8/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2513 - accuracy: 0.9026 - val_loss: 0.3543 - val_accuracy: 0.8706\n",
      "Epoch 9/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2408 - accuracy: 0.9081 - val_loss: 0.3647 - val_accuracy: 0.8676\n",
      "Epoch 10/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2379 - accuracy: 0.9026 - val_loss: 0.3730 - val_accuracy: 0.8412\n",
      "[CV] END ...........................batch_size=10, epochs=10; total time=   2.2s\n",
      "Epoch 1/10\n",
      "109/109 [==============================] - 1s 2ms/step - loss: 0.5172 - accuracy: 0.8153 - val_loss: 0.4131 - val_accuracy: 0.8412\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3914 - accuracy: 0.8447 - val_loss: 0.3625 - val_accuracy: 0.8559\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3404 - accuracy: 0.8621 - val_loss: 0.3343 - val_accuracy: 0.8735\n",
      "Epoch 4/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.8778 - val_loss: 0.3325 - val_accuracy: 0.8706\n",
      "Epoch 5/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2930 - accuracy: 0.8906 - val_loss: 0.3336 - val_accuracy: 0.8676\n",
      "Epoch 6/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2825 - accuracy: 0.8925 - val_loss: 0.3380 - val_accuracy: 0.8676\n",
      "Epoch 7/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2735 - accuracy: 0.8879 - val_loss: 0.3406 - val_accuracy: 0.8706\n",
      "Epoch 8/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2671 - accuracy: 0.8915 - val_loss: 0.3423 - val_accuracy: 0.8618\n",
      "Epoch 9/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2646 - accuracy: 0.8934 - val_loss: 0.3476 - val_accuracy: 0.8588\n",
      "Epoch 10/10\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 0.2548 - accuracy: 0.8998 - val_loss: 0.3598 - val_accuracy: 0.8559\n",
      "[CV] END ...........................batch_size=10, epochs=10; total time=   2.0s\n",
      "Epoch 1/5\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6206 - accuracy: 0.8024 - val_loss: 0.5861 - val_accuracy: 0.8382\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5368 - accuracy: 0.8401 - val_loss: 0.4996 - val_accuracy: 0.8412\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.8401 - val_loss: 0.4496 - val_accuracy: 0.8412\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.8401 - val_loss: 0.4328 - val_accuracy: 0.8412\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8401 - val_loss: 0.4233 - val_accuracy: 0.8412\n",
      "[CV] END ...........................batch_size=100, epochs=5; total time=   0.7s\n",
      "Epoch 1/5\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6286 - accuracy: 0.7914 - val_loss: 0.5836 - val_accuracy: 0.8382\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.8392 - val_loss: 0.5153 - val_accuracy: 0.8412\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.8401 - val_loss: 0.4667 - val_accuracy: 0.8412\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.8401 - val_loss: 0.4429 - val_accuracy: 0.8412\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.8401 - val_loss: 0.4307 - val_accuracy: 0.8412\n",
      "[CV] END ...........................batch_size=100, epochs=5; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.5889 - accuracy: 0.8401 - val_loss: 0.5485 - val_accuracy: 0.8412\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.8401 - val_loss: 0.4816 - val_accuracy: 0.8412\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.8401 - val_loss: 0.4455 - val_accuracy: 0.8412\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.8401 - val_loss: 0.4334 - val_accuracy: 0.8412\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8401 - val_loss: 0.4251 - val_accuracy: 0.8412\n",
      "[CV] END ...........................batch_size=100, epochs=5; total time=   0.7s\n",
      "Epoch 1/5\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6308 - accuracy: 0.7914 - val_loss: 0.5774 - val_accuracy: 0.8471\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5462 - accuracy: 0.8392 - val_loss: 0.5045 - val_accuracy: 0.8412\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.8410 - val_loss: 0.4563 - val_accuracy: 0.8412\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.8410 - val_loss: 0.4309 - val_accuracy: 0.8412\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.8410 - val_loss: 0.4188 - val_accuracy: 0.8412\n",
      "[CV] END ...........................batch_size=100, epochs=5; total time=   0.7s\n",
      "Epoch 1/5\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6808 - accuracy: 0.6029 - val_loss: 0.6550 - val_accuracy: 0.7647\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.8318 - val_loss: 0.6056 - val_accuracy: 0.8412\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5826 - accuracy: 0.8410 - val_loss: 0.5505 - val_accuracy: 0.8412\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5285 - accuracy: 0.8410 - val_loss: 0.4962 - val_accuracy: 0.8412\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.8410 - val_loss: 0.4547 - val_accuracy: 0.8412\n",
      "[CV] END ...........................batch_size=100, epochs=5; total time=   0.7s\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.9262 - accuracy: 0.1645 - val_loss: 0.8290 - val_accuracy: 0.1765\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7600 - accuracy: 0.2840 - val_loss: 0.6992 - val_accuracy: 0.4824\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6645 - accuracy: 0.6976 - val_loss: 0.6367 - val_accuracy: 0.8324\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6206 - accuracy: 0.8364 - val_loss: 0.6045 - val_accuracy: 0.8412\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.8401 - val_loss: 0.5768 - val_accuracy: 0.8412\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.8401 - val_loss: 0.5488 - val_accuracy: 0.8412\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.8401 - val_loss: 0.5202 - val_accuracy: 0.8412\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.8401 - val_loss: 0.4928 - val_accuracy: 0.8412\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.8401 - val_loss: 0.4685 - val_accuracy: 0.8412\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.8401 - val_loss: 0.4479 - val_accuracy: 0.8412\n",
      "[CV] END ..........................batch_size=100, epochs=10; total time=   0.9s\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.5878 - accuracy: 0.8070 - val_loss: 0.5254 - val_accuracy: 0.8412\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.8401 - val_loss: 0.4538 - val_accuracy: 0.8412\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.8401 - val_loss: 0.4274 - val_accuracy: 0.8412\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8401 - val_loss: 0.4173 - val_accuracy: 0.8412\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8401 - val_loss: 0.4060 - val_accuracy: 0.8412\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3911 - accuracy: 0.8401 - val_loss: 0.3962 - val_accuracy: 0.8412\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3793 - accuracy: 0.8401 - val_loss: 0.3869 - val_accuracy: 0.8412\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3671 - accuracy: 0.8419 - val_loss: 0.3778 - val_accuracy: 0.8441\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.8428 - val_loss: 0.3696 - val_accuracy: 0.8471\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.8456 - val_loss: 0.3633 - val_accuracy: 0.8412\n",
      "[CV] END ..........................batch_size=100, epochs=10; total time=   0.9s\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 1s 36ms/step - loss: 0.5915 - accuracy: 0.8410 - val_loss: 0.5475 - val_accuracy: 0.8441\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5187 - accuracy: 0.8401 - val_loss: 0.4812 - val_accuracy: 0.8412\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.8401 - val_loss: 0.4372 - val_accuracy: 0.8412\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.8401 - val_loss: 0.4169 - val_accuracy: 0.8412\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8401 - val_loss: 0.4067 - val_accuracy: 0.8412\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8401 - val_loss: 0.3973 - val_accuracy: 0.8412\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.8401 - val_loss: 0.3877 - val_accuracy: 0.8412\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3751 - accuracy: 0.8401 - val_loss: 0.3773 - val_accuracy: 0.8412\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3615 - accuracy: 0.8428 - val_loss: 0.3674 - val_accuracy: 0.8529\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.8493 - val_loss: 0.3582 - val_accuracy: 0.8559\n",
      "[CV] END ..........................batch_size=100, epochs=10; total time=   1.1s\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.7964 - accuracy: 0.1783 - val_loss: 0.7427 - val_accuracy: 0.2324\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7141 - accuracy: 0.3851 - val_loss: 0.6852 - val_accuracy: 0.5971\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6696 - accuracy: 0.7335 - val_loss: 0.6499 - val_accuracy: 0.8324\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.8300 - val_loss: 0.6162 - val_accuracy: 0.8441\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5977 - accuracy: 0.8410 - val_loss: 0.5723 - val_accuracy: 0.8441\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.8419 - val_loss: 0.5096 - val_accuracy: 0.8412\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.8419 - val_loss: 0.4525 - val_accuracy: 0.8412\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8419 - val_loss: 0.4265 - val_accuracy: 0.8412\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8419 - val_loss: 0.4130 - val_accuracy: 0.8412\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 0.8456 - val_loss: 0.3995 - val_accuracy: 0.8529\n",
      "[CV] END ..........................batch_size=100, epochs=10; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6355 - accuracy: 0.7665 - val_loss: 0.5817 - val_accuracy: 0.8412\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5513 - accuracy: 0.8401 - val_loss: 0.5081 - val_accuracy: 0.8412\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.8410 - val_loss: 0.4662 - val_accuracy: 0.8412\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.8410 - val_loss: 0.4510 - val_accuracy: 0.8412\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.8410 - val_loss: 0.4422 - val_accuracy: 0.8412\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.8410 - val_loss: 0.4326 - val_accuracy: 0.8412\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.8410 - val_loss: 0.4230 - val_accuracy: 0.8412\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8410 - val_loss: 0.4137 - val_accuracy: 0.8412\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8410 - val_loss: 0.4026 - val_accuracy: 0.8412\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3890 - accuracy: 0.8428 - val_loss: 0.3914 - val_accuracy: 0.8412\n",
      "[CV] END ..........................batch_size=100, epochs=10; total time=   0.9s\n",
      "Epoch 1/10\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.4265 - accuracy: 0.8338 - val_loss: 0.3775 - val_accuracy: 0.8412\n",
      "Epoch 2/10\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.3486 - accuracy: 0.8559 - val_loss: 0.3432 - val_accuracy: 0.8588\n",
      "Epoch 3/10\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.3056 - accuracy: 0.8860 - val_loss: 0.3337 - val_accuracy: 0.8765\n",
      "Epoch 4/10\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.2830 - accuracy: 0.8926 - val_loss: 0.3384 - val_accuracy: 0.8765\n",
      "Epoch 5/10\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.2748 - accuracy: 0.8882 - val_loss: 0.3352 - val_accuracy: 0.8765\n",
      "Epoch 6/10\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.2611 - accuracy: 0.8904 - val_loss: 0.3517 - val_accuracy: 0.8735\n",
      "Epoch 7/10\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.2562 - accuracy: 0.9029 - val_loss: 0.3454 - val_accuracy: 0.8588\n",
      "Epoch 8/10\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.8971 - val_loss: 0.3457 - val_accuracy: 0.8647\n",
      "Epoch 9/10\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.9037 - val_loss: 0.3665 - val_accuracy: 0.8500\n",
      "Epoch 10/10\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.2362 - accuracy: 0.9110 - val_loss: 0.3573 - val_accuracy: 0.8588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x0000021D5AB8F5C0>,\n",
       "                   n_iter=6,\n",
       "                   param_distributions={'batch_size': [5, 10, 100],\n",
       "                                        'epochs': [5, 10]},\n",
       "                   random_state=111, scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train again\n",
    "rnd_search_cv2.fit(new_X_train, y_train, validation_data=(new_X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bb00ffca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.5300501598411302\n"
     ]
    }
   ],
   "source": [
    "#print('Best Score: %s' % rnd_search_cv2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d7e5dff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 10, 'batch_size': 5}\n",
      "0.5300501598411302\n"
     ]
    }
   ],
   "source": [
    "# F1 score of this FCN model looks similar to machine learning\n",
    "# Also close to MLP f1 score on the training dataset, but MLP looks a bit better.\n",
    "best_sequ_param = rnd_search_cv2.best_params_\n",
    "best_sequ_score = rnd_search_cv2.best_score_\n",
    "print(best_sequ_param)\n",
    "print(best_sequ_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "ae354c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.4471 - val_loss: 0.3858\n",
      "Epoch 2/10\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.3578 - val_loss: 0.3480\n",
      "Epoch 3/10\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.3155 - val_loss: 0.3281\n",
      "Epoch 4/10\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.2924 - val_loss: 0.3251\n",
      "Epoch 5/10\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.2796 - val_loss: 0.3288\n",
      "Epoch 6/10\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.2684 - val_loss: 0.3336\n",
      "Epoch 7/10\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.2655 - val_loss: 0.3376\n",
      "Epoch 8/10\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.2552 - val_loss: 0.3452\n",
      "Epoch 9/10\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.2513 - val_loss: 0.3477\n",
      "Epoch 10/10\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.2472 - val_loss: 0.3495\n"
     ]
    }
   ],
   "source": [
    "# Use the best parameters that we found before to bring in the model with other same conditions and check the result\n",
    "best_param_model = keras.models.Sequential([\n",
    "    keras.layers.Dense(16, activation=\"relu\", input_shape = [98]),\n",
    "    keras.layers.Dense(16, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "best_param_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "history = best_param_model.fit(new_X_train, y_train, epochs=10, batch_size=10, validation_data=(new_X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "501f19d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                1584      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,873\n",
      "Trainable params: 1,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Use summary to check the model, and it looks the same\n",
    "best_param_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "0b37a5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if it's a good fit model by learning curve\n",
    "# In FCN sequential API, from the result of the learning curve, the loss in training decreases and maintains. \n",
    "# On the other hand, the loss in validation/testing has the same pattern. The training loss is smaller than validation/testing in the end. \n",
    "# Also, their loss is close eventually. However, it would be better if the validation loss was slightly greater than the training loss. \n",
    "# Therefore, I think the fit of the model is okay, but could be better.\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "54cd85f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'val_loss'])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d9a1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
